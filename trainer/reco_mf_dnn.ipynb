{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, re, codecs, seaborn as sns, json, time, csv, datetime as dt\n",
    "import pickle, collections, random, math, numbers, scipy.sparse as sp, matplotlib.pyplot as plt, scipy.sparse as sp\n",
    "\n",
    "def reload(mName):\n",
    "    import importlib\n",
    "    if mName in sys.modules:\n",
    "        del sys.modules[mName]\n",
    "    return importlib.import_module(mName)\n",
    "\n",
    "\n",
    "from collections import deque, defaultdict, OrderedDict\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, minmax_scale\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# classpath\n",
    "ctx = os.path.abspath('..')\n",
    "cps = [ctx]\n",
    "_ = [sys.path.insert(0, cp) for cp in cps if cp not in sys.path]\n",
    "\n",
    "# data path\n",
    "datapath = '/'.join([ctx, 'data'])\n",
    "\n",
    "utils = reload('utils.utils')\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100004, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>859</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       0       30     2.5  1260759144\n",
       "1       0      833     3.0  1260759179\n",
       "2       0      859     3.0  1260759182\n",
       "3       0      906     2.0  1260759185\n",
       "4       0      931     4.0  1260759205"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"{}/ml-latest-small/ratings.csv\".format(datapath))\n",
    "movies = pd.read_csv(\"{}/ml-latest-small/movies.csv\".format(datapath))\n",
    "tags = pd.read_csv(\"{}/ml-latest-small/tags.csv\".format(datapath))\n",
    "\n",
    "uidEnc, midEnc = LabelEncoder(), LabelEncoder()\n",
    "# encode user id and movie id to real value\n",
    "midEnc.fit(movies.movieId)\n",
    "uidEnc.fit(ratings.userId)\n",
    "\n",
    "ratings[\"userId\"] = uidEnc.transform(ratings.userId)\n",
    "ratings[\"movieId\"] = midEnc.transform(ratings.movieId)\n",
    "\n",
    "movies[\"movieId\"] = midEnc.transform(movies.movieId)\n",
    "\n",
    "tags[\"userId\"] = uidEnc.transform(tags.userId)\n",
    "tags[\"movieId\"] = midEnc.transform(tags.movieId)\n",
    "\n",
    "midMap = pd.Series(dict(zip(movies.movieId, movies.title)))\n",
    "\n",
    "nUsers, nMovies = len(uidEnc.classes_), len(midEnc.classes_)\n",
    "\n",
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train interaction matrix shape:  (671, 9125) test interaction matrix shape:  (671, 9125)\n",
      "train.shape:  (69399, 4) test.shape:  (30605, 4)\n",
      "\n",
      "   userId  movieId  rating   timestamp\n",
      "0       0      931     4.0  1260759205\n",
      "1       0     1515     4.0  1260759191\n",
      "2       0       30     2.5  1260759144\n",
      "3       0      833     3.0  1260759179\n",
      "4       0      859     3.0  1260759182\n",
      "\n",
      "   userId  movieId  rating   timestamp\n",
      "0       0     1665     4.0  1260759139\n",
      "1       0     1708     3.0  1260759194\n",
      "2       0     1743     2.0  1260759198\n",
      "3       0     1815     2.0  1260759108\n",
      "4       0     1962     2.5  1260759113\n"
     ]
    }
   ],
   "source": [
    "tr = pd.read_csv(\"{}/ml-latest-small/movielens.tr.csv\".format(datapath))\n",
    "te = pd.read_csv(\"{}/ml-latest-small/movielens.te.csv\".format(datapath))\n",
    "\n",
    "# state = utils.loadPickle(\"./data/ml-latest-small/state.h\")\n",
    "# uidEnc, midEnc, midMap, nUsers, nMovies = \\\n",
    "#     (state[\"uidEnc\"], state[\"midEnc\"], state[\"midMap\"], state[\"nUsers\"], state[\"nMovies\"])\n",
    "\n",
    "# train data rating matrix\n",
    "trRatingMat = np.zeros((nUsers, nMovies))\n",
    "# test data rating matrix\n",
    "teRatingMat = np.zeros((nUsers, nMovies))\n",
    "for idx, r in tr.iterrows():\n",
    "    trRatingMat[int(r.userId), int(r.movieId)] = r.rating\n",
    "for idx, r in te.iterrows():\n",
    "    teRatingMat[int(r.userId), int(r.movieId)] = r.rating\n",
    "\n",
    "print(\"train interaction matrix shape: \", trRatingMat.shape, \"test interaction matrix shape: \", teRatingMat.shape)\n",
    "print(\"train.shape: \", tr.shape, \"test.shape: \", te.shape)\n",
    "print()\n",
    "print(tr.head())\n",
    "print()\n",
    "print(te.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, movie_trans, train_hist=None, is_train=True):\n",
    "    queue = []\n",
    "    data = data.merge(movie_trans, how=\"left\", on=\"movieId\")\n",
    "    columns=[\"user_id\", \"query_movie_ids\", \n",
    "             \"genres\", \"avg_rating\", \"year\", \"candidate_movie_id\",\n",
    "             \"rating\"]\n",
    "    for u, df in data.groupby(\"userId\"):\n",
    "        df = df.sort_values(\"rating\", ascending=False)\n",
    "        if not is_train:\n",
    "            user_movies_hist = train_hist.query(\"userId == {}\".format(u)).movieId\n",
    "        for i, (_, r) in enumerate(df.iterrows()):\n",
    "            if is_train:\n",
    "                queue.append([int(r.userId), df.movieId[:i].tolist() + df.movieId[i + 1:].tolist(), r.genres, r.avg_rating, r.year, int(r.movieId), r.rating])\n",
    "            else:\n",
    "                # queue.append([int(r.userId), df.movieId[:i].tolist() + df.movieId[i + 1:].tolist(), r.genres, r.avg_rating, r.year, int(r.movieId), r.rating])\n",
    "                # all_hist = set(user_movies_hist.tolist() + df.movieId[:i].tolist())\n",
    "                all_hist = set(user_movies_hist.tolist())\n",
    "                queue.append([int(r.userId), list(all_hist - set([int(r.movieId)])), r.genres, r.avg_rating, r.year, int(r.movieId), r.rating])\n",
    "    return pd.DataFrame(queue, columns=columns)\n",
    "\n",
    "movie_trans, genres_enc = utils.doMovies(movies)\n",
    "movie_trans[\"avg_rating\"] = ratings.groupby(\"movieId\").rating.mean()\n",
    "movie_trans[\"avg_rating\"] = minmax_scale(movie_trans.avg_rating.fillna(ratings.rating.mean()))\n",
    "movie_trans[\"year\"] = movie_trans.title.str.findall(\"\\(\\s*(\\d+)\\s*\\)\").map(lambda lst: int(lst[-1]) if len(lst) else None)\n",
    "movie_trans[\"year\"] = minmax_scale(movie_trans.year.fillna(movie_trans.year.median()))\n",
    "n_genres = len(genres_enc.enc_)\n",
    "\n",
    "trProcessed = preprocess(tr, movie_trans)\n",
    "teProcessed = preprocess(te, movie_trans, tr, is_train=False)\n",
    "trProcessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teProcessed['query_movie_ids'] = teProcessed.query_movie_ids.map(lambda r: ','.join(map(str, r))) \n",
    "teProcessed['genres'] = teProcessed.genres.map(lambda r: ','.join(map(str, r)))\n",
    "teProcessed.to_csv('./te_processed.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_multi(df, multi_cols):\n",
    "    \"\"\"對於multivalent的欄位, 需要增加一個column去描述該欄位的長度\"\"\"\n",
    "    pad = tf.keras.preprocessing.sequence.pad_sequences\n",
    "    ret = OrderedDict()\n",
    "    for colname, col in df.iteritems():\n",
    "        if colname in multi_cols:\n",
    "            lens = col.map(len)\n",
    "            ret[colname] = list(pad(col, padding=\"post\", maxlen=lens.max()))\n",
    "            ret[colname + \"_len\"] = lens.values\n",
    "        else:\n",
    "            ret[colname] = col.values\n",
    "    return ret\n",
    "\n",
    "def dataFn(data, n_batch=128, shuffle=False):\n",
    "    pad = tf.keras.preprocessing.sequence.pad_sequences\n",
    "    def fn():\n",
    "        dataInner = data.copy()\n",
    "        indices = utils.get_minibatches_idx(len(dataInner), n_batch, shuffle=shuffle)\n",
    "        for ind in indices:\n",
    "            yield do_multi(dataInner.iloc[ind], [\"query_movie_ids\", \"genres\"])\n",
    "    return fn\n",
    "\n",
    "for i, e in enumerate(dataFn(trProcessed, n_batch=5, shuffle=True)(), 1):\n",
    "    break\n",
    "pd.DataFrame(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF with DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='./model/reco_mf_dnn'\n",
    "dim = 16\n",
    "lr = 0.005\n",
    "n_batch = 128\n",
    "\n",
    "reco_mf_dnn = reload('reco_mf_dnn.reco_mf_dnn_flex_shema')\n",
    "tf.reset_default_graph()\n",
    "model = reco_mf_dnn.ModelMfDNN(nUsers, nMovies, dim=dim, learning_rate=lr, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-23304bf634f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_rating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'xxx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=model.graph) as sess:\n",
    "    model.fit(sess, \n",
    "              dataFn(trProcessed, n_batch, shuffle=True), \n",
    "              dataFn(teProcessed, n_batch, shuffle=False), reset=True, n_epoch=10)\n",
    "# 0.526"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 觀察單一user與預測分布圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_item_data(data, uids, movie_trans, n_batch=128):\n",
    "    u_col = [\"user_id\", \"query_movie_ids\"]\n",
    "    cache = {\"u_ary\": []}\n",
    "    items = do_multi(movie_trans, [\"genres\"])\n",
    "    items[\"candidate_movie_id\"] = items.pop(\"movieId\")\n",
    "    def clear(u_ary):\n",
    "        u_data = do_multi(pd.DataFrame(data=u_ary, columns=u_col), [\"query_movie_ids\"])\n",
    "        cache[\"u_ary\"] = []\n",
    "        return u_data\n",
    "    \n",
    "    for uid, df in data[data.user_id.isin(uids)].groupby(\"user_id\"):\n",
    "        u_rec, u_ary = df.iloc[0], cache[\"u_ary\"]\n",
    "        # print(u_rec.query_movie_ids, u_rec.candidate_movie_id)\n",
    "        u_rec.set_value(\"query_movie_ids\", u_rec.query_movie_ids + [u_rec.candidate_movie_id])\n",
    "        u_ary.append(u_rec[u_col].values)\n",
    "        if len(u_ary) >= n_batch:\n",
    "            yield clear(u_ary), items\n",
    "    yield clear(u_ary), items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# user id from 0 ~ 670\n",
    "uid = 22\n",
    "u_queries, movies_meta = list(user_item_data(trProcessed, [uid], movie_trans))[0]\n",
    "with tf.Session(graph=model.graph) as sess:\n",
    "    pred = model.predict(sess, u_queries, movies_meta)\n",
    "print(\"shape: \", pred.shape, pred)\n",
    "\n",
    "nnzCoord = teRatingMat[uid].nonzero()\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_title(\"pred distribution\")\n",
    "pd.Series(pred.ravel()[nnzCoord]).hist(bins=30, ax=ax[0])\n",
    "ax[1].set_title(\"real distribution\")\n",
    "pd.Series(map(lambda e: e, teRatingMat[uid][nnzCoord])).hist(bins=30, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 可給定user id細看每個user的rating與model預測效果\n",
    "# valid user id from 0 ~ 670\n",
    "uid = 23\n",
    "with tf.Session(graph=model.graph) as sess:\n",
    "    u_queries, movies_meta = list(user_item_data(teProcessed, [uid], movie_trans))[0]\n",
    "    recomm = model.predict(\n",
    "        sess, \n",
    "        u_queries, \n",
    "        movies_meta\n",
    "    ).ravel()\n",
    "recommDf = pd.DataFrame(data={\n",
    "              \"userId\": uid,\n",
    "              \"movieId\": range(len(recomm)), \n",
    "              \"title\": midMap[np.arange(len(recomm))].values, \n",
    "              \"rating\": teRatingMat[uid, range(len(recomm))],\n",
    "              \"predRating\": recomm},\n",
    "             columns=(\"userId\", \"movieId\", \"title\", \"rating\", \"predRating\"))\n",
    "# ascending 可以調整True or False觀察結果\n",
    "recommDf.query(\"rating != 0\").sort_values(\"rating\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommDf.query(\"rating != 0\").sort_values(\"predRating\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def drawRocCurve(y, predProba):\n",
    "    fprRf, tprRf, _ = roc_curve(y, predProba, pos_label=1)\n",
    "    aucScr = auc(fprRf, tprRf)\n",
    "    print(\"auc:\", aucScr)\n",
    "    f, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.plot(fprRf, tprRf, label='ROC CURVE')\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.set_title('AOC: Area Under Curve (score: {:.4f})'.format(aucScr))\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "with tf.Session(graph=model.graph) as sess:\n",
    "    model.ckpt(sess, model.model_dir)\n",
    "    labels, preds = [], []\n",
    "    for data in dataFn(teProcessed)():\n",
    "        labels.append(data['rating'])\n",
    "        preds.append(sess.run(model.gmf, model.feed_dict(data, mode=\"eval\")).ravel())\n",
    "# regard rating >= 4 as user like this movie\n",
    "drawRocCurve((np.concatenate(labels) >= 4).astype(int), np.concatenate(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG: Normalized Discounted Cumulative Gain\n",
    "1. A measure of ranking quality.\n",
    "2. loop 每一位user, prediciton score排序後計算NDCG\n",
    "    <br/>$$ DCG_p = \\sum^p_{i = 1} \\frac{2^{rel_i} - 1}{log_2(i + 1)} $$<br/>\n",
    "3. IDCG: Ideal DCG, 為理想狀態下的DCG分數, 即model全部命中的DCG分數, 而NDCG: Normalized DCG, 公式如下\n",
    "    <br/>$$ NDCG_p = \\sum^p_{i = 1} \\frac{DCG_p}{IDCG_p} $$<br/>\n",
    "4. 所以NDCG是一個比值, 介於0 ~ 1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strict_condition(label):\n",
    "    label = label[label != 0]\n",
    "    pos, neg = sum(label >= 4), sum(label < 4)\n",
    "    return len(label) >= 10 and pos <= neg and pos > 0\n",
    "    \n",
    "print(\"rating數量 >= 10 且 負評價數量 >= 正評價數量 有 [{}] 人\".format(sum(strict_condition(label) for label in teRatingMat)))\n",
    "\n",
    "def norm_condition(label):\n",
    "    label = label[label != 0]\n",
    "    return sum(label >= 4) > 0 and sum(label < 4) > 0\n",
    "print(\"rating正評價數量 >= 0 且 rating負評價數量 >= 0 有 [{}] 人\".format(sum(norm_condition(label) for label in teRatingMat)))\n",
    "\n",
    "def single_user_ndcg(label, score, label_thres=4, k=10):\n",
    "    \"\"\"single user ndcg score\"\"\"\n",
    "    nnz = label.nonzero()[0]\n",
    "    # if np.sum(label >= label_thres) < k: return None\n",
    "    label, score = label[nnz], score[nnz]\n",
    "    label = (label >= label_thres).astype(int)\n",
    "    return utils.ndcg_score(label, score, k)\n",
    "\n",
    "def all_user_ndcg(label, pred_mat, cond_fn, label_thres=4, k=10):\n",
    "    \"\"\"avg of all user ndcg score\"\"\"\n",
    "    tot_ndcg, actual_cnt = 0, 0\n",
    "    for i, (label, score) in enumerate(zip(teRatingMat, pred_mat)):\n",
    "        if not cond_fn(label): continue\n",
    "\n",
    "        ndcg = single_user_ndcg(label, score, k=10)\n",
    "        if ndcg is not None:\n",
    "            tot_ndcg += ndcg\n",
    "            actual_cnt += 1\n",
    "    return tot_ndcg / actual_cnt\n",
    "\n",
    "with tf.Session(graph=model.graph) as sess:\n",
    "    pred_mat = []\n",
    "    for u_data, items in user_item_data(teProcessed, np.arange(nUsers), movie_trans, n_batch=128):\n",
    "        pred_mat.append(model.predict(sess, u_data, items))\n",
    "    pred_mat = np.vstack(pred_mat)\n",
    "    \n",
    "strict_ndcg = all_user_ndcg(teRatingMat, pred_mat, strict_condition, label_thres=4, k=10)\n",
    "norm_ndcg = all_user_ndcg(teRatingMat, pred_mat, norm_condition, label_thres=4, k=10)\n",
    "print(\"strict condition ndcg at 10: \", strict_ndcg)\n",
    "print(\"norm condition ndcg at 10: \", norm_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...</td>\n",
       "      <td>3, 5, 8</td>\n",
       "      <td>0.661939</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>1665</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...</td>\n",
       "      <td>5, 1</td>\n",
       "      <td>0.669753</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1708</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...</td>\n",
       "      <td>1, 16</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>2925</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...</td>\n",
       "      <td>0, 7, 8, 2</td>\n",
       "      <td>0.643026</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1962</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...</td>\n",
       "      <td>3, 5, 9</td>\n",
       "      <td>0.600529</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>1743</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    query_movie_ids      genres  \\\n",
       "0        0  833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...     3, 5, 8   \n",
       "1        0  833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...        5, 1   \n",
       "2        0  833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...       1, 16   \n",
       "3        0  833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...  0, 7, 8, 2   \n",
       "4        0  833, 931, 1083, 906, 1515, 1041, 1140, 1111, 1...     3, 5, 9   \n",
       "\n",
       "   avg_rating      year  candidate_movie_id  rating  \n",
       "0    0.661939  0.701754                1665     4.0  \n",
       "1    0.669753  0.684211                1708     3.0  \n",
       "2    0.763441  0.631579                2925     3.0  \n",
       "3    0.643026  0.736842                1962     2.5  \n",
       "4    0.600529  0.754386                1743     2.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "teProcessed = pd.read_csv('./te_processed.csv', names=headers)\n",
    "# teProcessed['query_movie_ids'] = teProcessed.query_movie_ids.str.replace('\\[(.+)\\]', '\\\\1')\n",
    "# teProcessed['genres'] = teProcessed.genres.str.replace('\\[(.+)\\]', '\\\\1')\n",
    "teProcessed.head() # .to_csv('./te_processed.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import sparse_tensor\n",
    "import re\n",
    "\n",
    "def to_sparse(dense):\n",
    "    idx = tf.where(tf.not_equal(dense, 0))\n",
    "    return tf.SparseTensor(idx, tf.gather_nd(dense, idx), dense.get_shape())\n",
    "\n",
    "def make_example(val):\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature = {\n",
    "            'query_movie_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=val)),\n",
    "            'genres': tf.train.Feature(int64_list=tf.train.Int64List(value=val))\n",
    "        }\n",
    "    ))\n",
    "    return example\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    filename = \"tmp.tfrecords\"\n",
    "    if not os.path.exists(filename):\n",
    "        # os.remove(filename)\n",
    "        writer = tf.python_io.TFRecordWriter(filename)\n",
    "        with writer:\n",
    "            for idx, r in teProcessed.head().iterrows():\n",
    "                for col in ('query_movie_ids', 'genres'):\n",
    "                    val = list(map(int, re.split(',\\s*', r[col])))\n",
    "                    ex = make_example(val)\n",
    "                    writer.write(ex.SerializeToString())\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    filename_queue = tf.train.string_input_producer([\"tmp.tfrecords\"], num_epochs=1)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    batch = tf.train.batch(tensors=[serialized_example], batch_size=1)\n",
    "    features = {\n",
    "        'query_movie_ids': tf.VarLenFeature(tf.int64),\n",
    "        'genres': tf.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    data = tf.parse_example(batch, features)\n",
    "    query_movie_ids = data['query_movie_ids']\n",
    "    embbedding = tf.Variable(tf.glorot_uniform_initializer()([9125]), dtype=tf.float32)\n",
    "    emb_query = tf.nn.embedding_lookup_sparse([embbedding], query_movie_ids, None, combiner='sqrtn')\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        try:\n",
    "            emb_query_ = sess.run(emb_query)\n",
    "            print(emb_query_)\n",
    "            pass\n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            coord.request_stop(e)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup_sparse:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "headers = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    # reader = tf.TextLineReader()\n",
    "    # _, value = reader.read(tf.train.string_input_producer(['./te_processed.csv']))\n",
    "    def parse_csv(value):\n",
    "        cols = tf.decode_csv(value, record_defaults=[[0], [''], [''], [], [], [0], []])\n",
    "        return OrderedDict(zip(headers, cols))\n",
    "    \n",
    "    def do_multi(*inputs):\n",
    "        r = OrderedDict(zip(headers, inputs))\n",
    "        r['query_movie_ids'] = re.split(',\\s*', r['query_movie_ids'])\n",
    "        return tuple(r.values())\n",
    "\n",
    "    dataset = tf.data.TextLineDataset(['./te_processed.csv'])\n",
    "    dataset = dataset.map(parse_csv)\\\n",
    "                     .map(lambda r: tf.py_func(do_multi, \n",
    "                                               [v for v in r.values()], \n",
    "                                               [tf.int32, tf.string, tf.string, tf.float32, tf.float32, tf.int32, tf.float32]))\\\n",
    "                     .batch(10)\n",
    "    iters = dataset.make_one_shot_iterator()\n",
    "    data = iters.get_next()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.tables_initializer().run()\n",
    "        data_ = sess.run(data)\n",
    "        \n",
    "        # coord = tf.train.Coordinator()\n",
    "        # threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        # try:\n",
    "        #     cur_data = sess.run(data)\n",
    "        #     print(cur_data)\n",
    "        # except tf.errors.OutOfRangeError as e:\n",
    "        #     coord.request_stop(e)\n",
    "        # finally:\n",
    "        #     coord.request_stop()\n",
    "        #     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.train.match_filenames_once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    reader = tf.TFRecordReader()\n",
    "    filename_queue = tf.train.string_input_producer([\"tmp.tfrecords\"], num_epochs=1)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # 'query_movie_ids', 'genres'\n",
    "    genres = tf.feature_column.categorical_column_with_hash_bucket('genres', hash_bucket_size=1000, dtype=tf.int64)\n",
    "    genres = tf.feature_column.embedding_column(genres, dimension=8)\n",
    "    query_movie_ids = tf.feature_column.categorical_column_with_hash_bucket('query_movie_ids', hash_bucket_size=1000, dtype=tf.int64)\n",
    "    query_movie_ids = tf.feature_column.embedding_column(query_movie_ids, dimension=8)\n",
    "    columns = [query_movie_ids, genres]\n",
    "    features = tf.parse_example(serialized_example, features=tf.feature_column.make_parse_example_spec(columns))\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
