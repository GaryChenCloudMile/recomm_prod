{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, re, codecs, seaborn as sns, json, time, csv, datetime as dt\n",
    "import pickle, collections, random, math, numbers, scipy.sparse as sp, matplotlib.pyplot as plt, scipy.sparse as sp\n",
    "\n",
    "from pprint import pprint\n",
    "from tensorflow.contrib.training.python.training.hparam import HParams\n",
    "\n",
    "def reload(mName):\n",
    "    import importlib\n",
    "    if mName in sys.modules:\n",
    "        del sys.modules[mName]\n",
    "    return importlib.import_module(mName)\n",
    "\n",
    "\n",
    "from collections import deque, defaultdict, OrderedDict\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, minmax_scale\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# classpath\n",
    "ctx = os.path.abspath('..').replace('\\\\', '/')\n",
    "cps = [ctx]\n",
    "_ = [sys.path.insert(0, cp) for cp in cps if cp not in sys.path]\n",
    "\n",
    "# data path\n",
    "datapath = '/'.join([ctx, 'data'])\n",
    "\n",
    "seed = 88\n",
    "utils = reload('trainer.utils.utils')\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "ratings = pd.read_csv(\"{}/ml-latest-small/ratings.csv\".format(datapath))\n",
    "ratings['timestamp'] = ratings.timestamp.map(dt.datetime.fromtimestamp).map(str)\n",
    "ratings['ori_rating'] = ratings['rating']\n",
    "ratings['rating'] = (ratings.rating >= 4).astype(int)\n",
    "tr, te = utils.split_by_ratio(ratings)\n",
    "\n",
    "movies = pd.read_csv(\"{}/ml-latest-small/movies.csv\".format(datapath))\n",
    "avg_rt = ratings.groupby(\"movieId\", as_index=False).ori_rating.mean().rename(index=str, columns={'ori_rating': 'avg_rating'})\n",
    "movies = movies.merge(avg_rt, how='left', on='movieId')\n",
    "# movies.avg_rating.fillna(ratings.rating.mean())\n",
    "movies[\"year\"] = movies.title.str.findall(\"\\(\\s*(\\d+)\\s*\\)\").map(lambda lst: int(lst[-1]) if len(lst) else None)\n",
    "# movies[\"year\"] = minmax_scale(movies.year.fillna(movies.year.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, movie_trans, train_hist=None, is_train=True):\n",
    "    queue = []\n",
    "    data = data.merge(movie_trans, how=\"left\", on=\"movieId\")\n",
    "    columns=[\"user_id\", \"query_movie_ids\",\n",
    "             \"genres\", \"avg_rating\", \"year\", \"candidate_movie_id\",\n",
    "             \"timestamp\",\n",
    "             \"rating\"]\n",
    "    \n",
    "    list2str = lambda lst: ','.join(map(str, lst))\n",
    "    for u, df in data.groupby(\"userId\"):\n",
    "        df = df.sort_values(\"rating\", ascending=False)\n",
    "        if not is_train:\n",
    "            user_movies_hist = train_hist.query(\"userId == {}\".format(u)).movieId\n",
    "        for i, (_, r) in enumerate(df.iterrows()):\n",
    "            if is_train:\n",
    "                query_hist = df.movieId[:i].tolist() + df.movieId[i + 1:].tolist()\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "            else:\n",
    "                tr_hist = set(user_movies_hist.tolist())\n",
    "                query_hist = list(tr_hist - set([int(r.movieId)]))\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "    return pd.DataFrame(queue, columns=columns)\n",
    "    \n",
    "tr_merged = preprocess(tr, movies)\n",
    "tr_merged.to_csv('./tr.raw.movielens.csv', index=False, header=None)\n",
    "\n",
    "te_merged = preprocess(te, movies, tr, is_train=False)\n",
    "te_merged.to_csv('./te.raw.movielens.csv', index=False, header=None)\n",
    "# 合併成一個檔案\n",
    "merged = pd.concat([tr_merged, te_merged], ignore_index=True)\n",
    "merged.to_csv('./merged_movielens.csv', index=False, header=None)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Cmd Submit Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cd D:/Python/notebook/recomm_prod && \\\n",
    "gcloud ml-engine jobs submit training recomm_movielens_15 \\\n",
    "    --job-dir gs://recomm-job/foo/model \\\n",
    "    --runtime-version 1.4 \\\n",
    "    --module-name trainer.ctrl \\\n",
    "    --package-path trainer \\\n",
    "    --region asia-east1 \\\n",
    "    --config config.yaml \\\n",
    "    -- \\\n",
    "    --method train \\\n",
    "    --conf-path gs://recomm-job/foo/data/user_supplied/movielens.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine jobs describe recomm_movielens_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && python setup.py build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Client API Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.training.python.training.hparam import HParams\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "hparam = HParams(conf_path='gs://movielens-foo/user_supplied/movielens.yaml')\n",
    "hparam.add_hparam('is_local', False)\n",
    "ctrl.gen_data(hparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-06 15:53:38,551 - Loader - INFO [line:363] - try to unserialize from gs://recomm-job/foo-bar/movielens_recommendation/data/parsed.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'col_states_': OrderedDict([('query_movie_ids',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=True,\n",
       "                     name='query_movie_ids', sep=',', vocabs=None, vocabs_path=None)),\n",
       "              ('genres',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=True, name='genres',\n",
       "                     sep='|', vocabs=None, vocabs_path=None)),\n",
       "              ('avg_rating', NumericMapper(default=None, name='avg_rating')),\n",
       "              ('year', NumericMapper(default=None, name='year')),\n",
       "              ('candidate_movie_id',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=False,\n",
       "                     name='candidate_movie_id', sep=None, vocabs=None, vocabs_path=None)),\n",
       "              ('rating',\n",
       "               CatgMapper(allow_null=False, default=None, is_multi=False, name='rating',\n",
       "                     sep=None, vocabs=None, vocabs_path=None))]),\n",
       " 'conf_': {'columns': [{'id': 'user_id', 'm_dtype': 'catg'},\n",
       "   {'id': 'query_movie_ids',\n",
       "    'is_multi': True,\n",
       "    'm_dtype': 'catg',\n",
       "    'sep': ',',\n",
       "    'vocabs_path': 'gs://movielens-foo/user_supplied/item.vocab'},\n",
       "   {'id': 'genres',\n",
       "    'is_multi': True,\n",
       "    'm_dtype': 'catg',\n",
       "    'sep': '|',\n",
       "    'vocabs_path': 'gs://movielens-foo/user_supplied/genres.vocab'},\n",
       "   {'id': 'avg_rating', 'm_dtype': 'cont'},\n",
       "   {'id': 'year', 'm_dtype': 'cont'},\n",
       "   {'id': 'candidate_movie_id',\n",
       "    'm_dtype': 'catg',\n",
       "    'vocabs_path': 'gs://movielens-foo/user_supplied/item.vocab'},\n",
       "   {'date_format': '%Y-%m-%d %H:%M:%S',\n",
       "    'id': 'timestamp',\n",
       "    'm_dtype': 'datetime'},\n",
       "   {'id': 'rating', 'm_dtype': 'catg'}],\n",
       "  'item': ['genres', 'avg_rating', 'year', 'candidate_movie_id'],\n",
       "  'label': ['rating'],\n",
       "  'model_id': 'movielens_recommendation',\n",
       "  'project_id': 'foo-bar',\n",
       "  'raw_dir': 'gs://movielens-foo/user_supplied/raws',\n",
       "  'user': ['query_movie_ids']},\n",
       " 'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml',\n",
       " 'count_': 100004,\n",
       " 'df_conf_':                                     id   m_dtype        date_format default  \\\n",
       " id                                                                            \n",
       " user_id                        user_id      catg               None    None   \n",
       " query_movie_ids        query_movie_ids      catg               None    None   \n",
       " genres                          genres      catg               None    None   \n",
       " avg_rating                  avg_rating      cont               None    None   \n",
       " year                              year      cont               None    None   \n",
       " candidate_movie_id  candidate_movie_id      catg               None    None   \n",
       " timestamp                    timestamp  datetime  %Y-%m-%d %H:%M:%S    None   \n",
       " rating                          rating      catg               None    None   \n",
       " \n",
       "                     is_multi   sep vocabs  \\\n",
       " id                                          \n",
       " user_id                False  None   None   \n",
       " query_movie_ids         True     ,   None   \n",
       " genres                  True     |   None   \n",
       " avg_rating             False  None   None   \n",
       " year                   False  None   None   \n",
       " candidate_movie_id     False  None   None   \n",
       " timestamp              False  None   None   \n",
       " rating                 False  None   None   \n",
       " \n",
       "                                                       vocabs_path    aux  \\\n",
       " id                                                                         \n",
       " user_id                                                      None  False   \n",
       " query_movie_ids       gs://movielens-foo/user_supplied/item.vocab  False   \n",
       " genres              gs://movielens-foo/user_supplied/genres.vocab  False   \n",
       " avg_rating                                                   None  False   \n",
       " year                                                         None  False   \n",
       " candidate_movie_id    gs://movielens-foo/user_supplied/item.vocab  False   \n",
       " timestamp                                                    None  False   \n",
       " rating                                                       None  False   \n",
       " \n",
       "                      type                                          col_state  \n",
       " id                                                                            \n",
       " user_id              None                                               None  \n",
       " query_movie_ids      user  allow_null: true\\nclasses_: ['1', '2', '3', '4...  \n",
       " genres               item  allow_null: true\\nclasses_: [(no genres listed...  \n",
       " avg_rating           item  {cumsum_: 354374.99999999907, default: null, m...  \n",
       " year                 item  {cumsum_: 199176755.0, default: null, max_: 20...  \n",
       " candidate_movie_id   item  allow_null: true\\nclasses_: ['1', '2', '3', '4...  \n",
       " timestamp            None                                               None  \n",
       " rating              label  allow_null: false\\nclasses_: ['0', '1']\\ndefau...  ,\n",
       " 'raw_paths': ['gs://movielens-foo/user_supplied/raws/merged_movielens.csv'],\n",
       " 'tr_count_': 70182,\n",
       " 'vl_count_': 29822}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.contrib.training.python.training.hparam import HParams\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
    "loader = ctrl.load_schema(params)\n",
    "\n",
    "vars(loader.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Python Client API Submit Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-06 16:54:48,147 - Ctrl - INFO [line:142] - foo-bar: gen_data take time 0:00:05.214712\n",
      "jobId: movielens_recommendation_20180306165443177431\n",
      "state: QUEUED\n",
      "D:\\Google\\Cloud SDK\\google-cloud-sdk\\lib\\googlecloudsdk\\core\\util\\files.py:622: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  for chunk in iter(lambda: fp.read(4096), ''):\n",
      "Job [movielens_recommendation_20180306165443177431] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe movielens_recommendation_20180306165443177431\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs movielens_recommendation_20180306165443177431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils = reload('trainer.utils.utils')\n",
    "reload('trainer.env')\n",
    "reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml',\n",
    "          'runtime_version': '1.4'}\n",
    "ret = ctrl.train_submit(params)\n",
    "job_id = ret.get('job_id')\n",
    "print( ret.get('response') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Describe Job States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-06 17:02:50,455 - googleapiclient.discovery - INFO [line:868] - URL being requested: GET https://ml.googleapis.com/v1/projects/training-recommendation-engine/jobs/movielens_recommendation_20180306165443177431?alt=json\n",
      "2018-03-06 17:02:50,457 - oauth2client.transport - INFO [line:151] - Attempting refresh to obtain initial access_token\n",
      "2018-03-06 17:02:50,489 - oauth2client.client - INFO [line:795] - Refreshing access_token\n",
      "2018-03-06 17:02:51,741 - Ctrl - INFO [line:160] - foo-bar: describe take time 0:00:01.405866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'createTime': '2018-03-06T08:54:45Z',\n",
       " 'endTime': '2018-03-06T09:02:39Z',\n",
       " 'jobId': 'movielens_recommendation_20180306165443177431',\n",
       " 'startTime': '2018-03-06T08:55:24Z',\n",
       " 'state': 'SUCCEEDED',\n",
       " 'trainingInput': {'args': ['--train-steps',\n",
       "   '1000',\n",
       "   '--method',\n",
       "   'train',\n",
       "   '--conf-path',\n",
       "   'gs://movielens-foo/user_supplied/movielens.yaml',\n",
       "   '--job-id',\n",
       "   'movielens_recommendation_20180306165443177431'],\n",
       "  'jobDir': 'gs://recomm-job/foo-bar/movielens_recommendation/model',\n",
       "  'packageUris': ['gs://recomm-job/foo-bar/movielens_recommendation/model/packages/3bbce4b391e6421266fbedaacbc4690883ca34ba045a61fc0078565b2978d84e/trainer-0.1.tar.gz'],\n",
       "  'pythonModule': 'trainer.ctrl',\n",
       "  'pythonVersion': '3.5',\n",
       "  'region': 'asia-east1',\n",
       "  'runtimeVersion': '1.4'},\n",
       " 'trainingOutput': {'consumedMLUnits': 0.1}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "\n",
    "env = reload('trainer.env')\n",
    "utils = reload('trainer.utils.utils')\n",
    "flex = reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
    "ret = ctrl.describe(params)\n",
    "ret['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-06 17:03:58,768 - Service - INFO [line:92] - try to create model [foo_bar_movielens_recommendation] ...\n",
      "2018-03-06 17:03:58,776 - googleapiclient.discovery - INFO [line:868] - URL being requested: POST https://ml.googleapis.com/v1/projects/training-recommendation-engine/models?alt=json\n",
      "2018-03-06 17:03:58,778 - oauth2client.transport - INFO [line:151] - Attempting refresh to obtain initial access_token\n",
      "2018-03-06 17:03:58,811 - oauth2client.client - INFO [line:795] - Refreshing access_token\n",
      "2018-03-06 17:04:00,087 - Service - WARNING [line:132] - <HttpError 409 when requesting https://ml.googleapis.com/v1/projects/training-recommendation-engine/models?alt=json returned \"Field: model.name Error: A model with the same name already exists.\">\n",
      "2018-03-06 17:04:00,089 - Service - INFO [line:95] - try to clean old version ...\n",
      "2018-03-06 17:04:00,100 - googleapiclient.discovery - INFO [line:868] - URL being requested: GET https://ml.googleapis.com/v1/projects/training-recommendation-engine/models/foo_bar_movielens_recommendation/versions?alt=json\n",
      "2018-03-06 17:04:00,359 - Service - INFO [line:140] - delete model version [projects/training-recommendation-engine/models/foo_bar_movielens_recommendation/versions/v20180306165500482317]\n",
      "2018-03-06 17:04:00,375 - googleapiclient.discovery - INFO [line:868] - URL being requested: DELETE https://ml.googleapis.com/v1/projects/training-recommendation-engine/models/foo_bar_movielens_recommendation/versions/v20180306165500482317?alt=json\n",
      "2018-03-06 17:04:01,472 - googleapiclient.discovery - INFO [line:868] - URL being requested: POST https://ml.googleapis.com/v1/projects/training-recommendation-engine/models/foo_bar_movielens_recommendation/versions?alt=json\n",
      "2018-03-06 17:04:03,710 - Service - INFO [line:116] - [foo_bar_movielens_recommendation] write deploy version name: v20180306170401467879\n",
      "2018-03-06 17:04:03,816 - FlexIO - INFO [line:559] - upload to [gs://recomm-job/foo-bar/movielens_recommendation/data/deploy.yaml]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'err_cde': '00',\n",
       " 'response': {'metadata': {'@type': 'type.googleapis.com/google.cloud.ml.v1.OperationMetadata',\n",
       "   'createTime': '2018-03-06T09:04:00Z',\n",
       "   'modelName': 'projects/training-recommendation-engine/models/foo_bar_movielens_recommendation',\n",
       "   'operationType': 'CREATE_VERSION',\n",
       "   'version': {'createTime': '2018-03-06T09:03:59Z',\n",
       "    'deploymentUri': 'gs://recomm-job/foo-bar/movielens_recommendation/model/export/export_foo-bar/1520326728',\n",
       "    'description': '[foo-bar] recommendation model',\n",
       "    'name': 'projects/training-recommendation-engine/models/foo_bar_movielens_recommendation/versions/v20180306170401467879',\n",
       "    'runtimeVersion': '1.4'}},\n",
       "  'name': 'projects/training-recommendation-engine/operations/create_foo_bar_movielens_recommendation_v20180306170401467879-1520327039058'}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "flex = reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
    "ret = ctrl.deploy(params)\n",
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Information From Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-06 17:04:14,426 - googleapiclient.discovery - INFO [line:868] - URL being requested: GET https://ml.googleapis.com/v1/projects/training-recommendation-engine/models/foo_bar_movielens_recommendation/versions/v20180306170401467879?alt=json\n",
      "2018-03-06 17:04:14,427 - oauth2client.transport - INFO [line:151] - Attempting refresh to obtain initial access_token\n",
      "2018-03-06 17:04:14,460 - oauth2client.client - INFO [line:795] - Refreshing access_token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'err_cde': '00',\n",
       " 'response': {'createTime': '2018-03-06T09:03:59Z',\n",
       "  'deploymentUri': 'gs://recomm-job/foo-bar/movielens_recommendation/model/export/export_foo-bar/1520326728',\n",
       "  'description': '[foo-bar] recommendation model',\n",
       "  'name': 'projects/training-recommendation-engine/models/foo_bar_movielens_recommendation/versions/v20180306170401467879',\n",
       "  'runtimeVersion': '1.4',\n",
       "  'state': 'CREATING'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "flex = reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
    "ret = ctrl.model_info(params)\n",
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restful predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-06 17:13:48,520 - Loader - INFO [line:363] - try to unserialize from gs://recomm-job/foo-bar/movielens_recommendation/data/parsed.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1953,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>2009-12-14 10:53:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.021739</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>2009-12-14 10:53:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>3.478723</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2105</td>\n",
       "      <td>2009-12-14 10:52:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,1029,1061,1129,1263,1287,1293,1...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2009-12-14 10:52:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,31,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Animation|Children|Drama|Musical</td>\n",
       "      <td>3.702381</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1029</td>\n",
       "      <td>2009-12-14 10:52:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    query_movie_ids  \\\n",
       "0        1  1953,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "1        1  1172,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "2        1  1172,1953,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "3        1  1172,1953,2105,1029,1061,1129,1263,1287,1293,1...   \n",
       "4        1  1172,1953,2105,31,1061,1129,1263,1287,1293,133...   \n",
       "\n",
       "                             genres  avg_rating    year  candidate_movie_id  \\\n",
       "0                             Drama    4.260870  1989.0                1172   \n",
       "1             Action|Crime|Thriller    4.021739  1971.0                1953   \n",
       "2           Action|Adventure|Sci-Fi    3.478723  1982.0                2105   \n",
       "3                             Drama    3.178571  1995.0                  31   \n",
       "4  Animation|Children|Drama|Musical    3.702381  1941.0                1029   \n",
       "\n",
       "             timestamp  rating  \n",
       "0  2009-12-14 10:53:25       1  \n",
       "1  2009-12-14 10:53:11       1  \n",
       "2  2009-12-14 10:52:19       1  \n",
       "3  2009-12-14 10:52:24       0  \n",
       "4  2009-12-14 10:52:59       0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ratings = pd.read_csv(\"{}/ml-latest-small/ratings.csv\".format(datapath))\n",
    "ratings['timestamp'] = ratings.timestamp.map(dt.datetime.fromtimestamp).map(str)\n",
    "ratings['ori_rating'] = ratings['rating']\n",
    "ratings['rating'] = (ratings.rating >= 4).astype(int)\n",
    "\n",
    "movies = pd.read_csv(\"{}/ml-latest-small/movies.csv\".format(datapath))\n",
    "avg_rt = ratings.groupby(\"movieId\", as_index=False).ori_rating.mean().rename(index=str, columns={'ori_rating': 'avg_rating'})\n",
    "movies = movies.merge(avg_rt, how='left', on='movieId')\n",
    "movies[\"year\"] = movies.title.str.findall(\"\\(\\s*(\\d+)\\s*\\)\").map(lambda lst: int(lst[-1]) if len(lst) else None)\n",
    "\n",
    "loader = ctrl.load_schema(params)\n",
    "merged = pd.read_csv('../data/foo/user_supplied/raws/merged_movielens.csv', names=loader.schema.raw_cols)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-06 17:54:59,573 - Loader - INFO [line:363] - try to unserialize from gs://recomm-job/foo-bar/movielens_recommendation/data/parsed.yaml\n",
      "2018-03-06 17:55:01,630 - Loader - INFO [line:451] - try to restful transform ... \n",
      "<class 'dict'>\n",
      "2018-03-06 17:55:01,715 - Ctrl - INFO [line:316] - foo-bar: predict take time 0:00:02.344979\n"
     ]
    }
   ],
   "source": [
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "flex = reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "user_id = 22\n",
    "data = {\n",
    "    'user_id': merged.query('user_id == {}'.format(user_id)).iloc[[0]].user_id.tolist(),\n",
    "    'query_movie_ids': merged.query('user_id == {}'.format(user_id)).iloc[[0]].query_movie_ids.tolist(),\n",
    "}\n",
    "items = movies.rename(index=str, columns={\"movieId\": \"candidate_movie_id\"}).drop('title', 1)\n",
    "items.loc[:, 'candidate_movie_id'] = items.candidate_movie_id.astype(str)\n",
    "items = items.to_dict('list')\n",
    "data.update(items)\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml',\n",
    "          'json_data': data}\n",
    "ret = ctrl.predict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[954,\n",
       "  1456,\n",
       "  1254,\n",
       "  1225,\n",
       "  1126,\n",
       "  1118,\n",
       "  1117,\n",
       "  1116,\n",
       "  1113,\n",
       "  1101,\n",
       "  1084,\n",
       "  1046,\n",
       "  1025,\n",
       "  1010,\n",
       "  995,\n",
       "  972,\n",
       "  967,\n",
       "  958,\n",
       "  1729,\n",
       "  1811,\n",
       "  1814,\n",
       "  2477,\n",
       "  3214,\n",
       "  3093,\n",
       "  3034,\n",
       "  2824,\n",
       "  2819,\n",
       "  2683,\n",
       "  2584,\n",
       "  2437,\n",
       "  1967,\n",
       "  2399,\n",
       "  2375,\n",
       "  2289,\n",
       "  2213,\n",
       "  2170,\n",
       "  2063,\n",
       "  2039,\n",
       "  956,\n",
       "  1404,\n",
       "  407,\n",
       "  562,\n",
       "  499,\n",
       "  428,\n",
       "  495,\n",
       "  523,\n",
       "  486,\n",
       "  525,\n",
       "  526,\n",
       "  226,\n",
       "  233,\n",
       "  143,\n",
       "  267,\n",
       "  696,\n",
       "  881,\n",
       "  2310,\n",
       "  208,\n",
       "  2402,\n",
       "  2373,\n",
       "  204,\n",
       "  2454,\n",
       "  185,\n",
       "  2397,\n",
       "  917,\n",
       "  2214,\n",
       "  2532,\n",
       "  240,\n",
       "  2181,\n",
       "  2175,\n",
       "  2174,\n",
       "  2169,\n",
       "  2162,\n",
       "  2161,\n",
       "  2148,\n",
       "  2140,\n",
       "  2478,\n",
       "  2646,\n",
       "  2554,\n",
       "  3001,\n",
       "  3217,\n",
       "  46,\n",
       "  3203,\n",
       "  3200,\n",
       "  3199,\n",
       "  3183,\n",
       "  47,\n",
       "  3060,\n",
       "  3046,\n",
       "  66,\n",
       "  2952,\n",
       "  153,\n",
       "  2894,\n",
       "  2861,\n",
       "  133,\n",
       "  138,\n",
       "  2744,\n",
       "  2720,\n",
       "  2682,\n",
       "  2095,\n",
       "  2637,\n",
       "  2610,\n",
       "  2130,\n",
       "  322,\n",
       "  2094,\n",
       "  522,\n",
       "  1346,\n",
       "  1337,\n",
       "  1310,\n",
       "  1306,\n",
       "  1295,\n",
       "  1280,\n",
       "  1235,\n",
       "  1130,\n",
       "  496,\n",
       "  520,\n",
       "  1115,\n",
       "  2085,\n",
       "  1112,\n",
       "  1066,\n",
       "  649,\n",
       "  1018,\n",
       "  650,\n",
       "  872,\n",
       "  971,\n",
       "  965,\n",
       "  959,\n",
       "  889,\n",
       "  1360,\n",
       "  1361,\n",
       "  1388,\n",
       "  43,\n",
       "  282,\n",
       "  321,\n",
       "  2005,\n",
       "  892,\n",
       "  1941,\n",
       "  1913,\n",
       "  1854,\n",
       "  1821,\n",
       "  392,\n",
       "  1765,\n",
       "  1676,\n",
       "  1642,\n",
       "  1586,\n",
       "  1574,\n",
       "  1569,\n",
       "  1560,\n",
       "  1487,\n",
       "  1481,\n",
       "  1474,\n",
       "  433,\n",
       "  1450,\n",
       "  3229]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict_keys(['avg_rating', 'query_movie_ids', 'genres', 'year', 'candidate_movie_id'])\n",
    "ret['response'].get('query_movie_ids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Local Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.training.python.training.hparam import HParams\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "flex = reload('trainer.utils.flex')\n",
    "service = reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': '../data/foo/user_supplied/movielens.local.yaml', 'is_local': True}\n",
    "ctrl.gen_data(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Local View Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "flex = reload('trainer.utils.flex')\n",
    "service = reload('trainer.service')\n",
    "\n",
    "with flex.io('../repo/foo-bar/movielens_recommendation/data/parsed.yaml').as_reader() as f:\n",
    "    schema = flex.Schema.unserialize(f.stream)\n",
    "vars(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.training.python.training.hparam import HParams\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "reload('trainer.reco_mf_dnn_est')\n",
    "flex = reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': '../data/foo/user_supplied/movielens.local.yaml', \n",
    "          'is_local': True,\n",
    "          'runtime_version': '1.4',\n",
    "          'train_steps': 1000}\n",
    "ctrl.train(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': {'export_path': 'gs://recomm-job/foo-bar/movielens_recommendation/model/export/export_foo-bar/1520326380', 'model_name': 'foo_bar_movielens_recommendation', 'job_id': 'movielens_recommendation_20180306165116939740', 'version': 'v20180306165500482317'}, 'err_cde': '00'}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.training.python.training.hparam import HParams\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "env = reload('trainer.env')\n",
    "reload('trainer.reco_mf_dnn_est')\n",
    "reload('trainer.utils.flex')\n",
    "reload('trainer.service')\n",
    "\n",
    "ctrl = reload('trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': '../data/foo/user_supplied/movielens.local.yaml', \n",
    "          'raw_dir': 'gs://recomm-job/foo-bar'}\n",
    "print(ctrl.test(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改GCS movielens.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.cloud.storage.blob import Blob\n",
    "from io import BytesIO\n",
    "\n",
    "utils = reload('trainer.utils.utils')\n",
    "flex = reload('trainer.utils.flex')\n",
    "env = reload('trainer.env')\n",
    "\n",
    "with flex.io('../data/foo/user_supplied/movielens.yaml') as r, \\\n",
    "    flex.io('gs://movielens-foo/user_supplied/movielens.yaml') as w:\n",
    "    w.write(r.read())\n",
    "\n",
    "# stream = BytesIO(open('../data/foo/user_supplied/movielens.yaml', mode='rb').read())\n",
    "# utils.gcs_blob('gs://movielens-foo/user_supplied/movielens.yaml').upload_from_file(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Python API Credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from google.cloud import storage\n",
    "\n",
    "authpath = '../auth.json'\n",
    "project = 'training-recommendation-engine'\n",
    "cred = GoogleCredentials.from_stream(authpath)\n",
    "svc = discovery.build('ml', 'v1', credentials=cred)\n",
    "\n",
    "st_client = storage.Client.from_service_account_json(authpath)\n",
    "bucket = st_client.get_bucket('recomm-job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO, BytesIO\n",
    "\n",
    "blob = bucket.get_blob('user_supplied/raws/merged_movielens.csv')\n",
    "sio = BytesIO()\n",
    "blob.download_to_file(sio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(data.keys())\n",
    "multi_cols = ('query_movie_ids', 'genres')\n",
    "\n",
    "def trans(features):\n",
    "    # features = OrderedDict(zip(cols, data))\n",
    "    print( schema.col_states_['query_movie_ids'].transform( features['query_movie_ids'] ) )\n",
    "    # for col in multi_cols:\n",
    "    #     features[col] = tf.string_to_number(tf.string_split(features[col], ',').values, out_type=tf.int32)\n",
    "    return features\n",
    "\n",
    "def add_seq_cols(feat):\n",
    "    for m_col in multi_cols:\n",
    "        name = '{}_len'.format(m_col)\n",
    "        feat[name] = tf.size(feat[m_col])\n",
    "        cols.append(name)\n",
    "    return feat\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    dataset = tf.data.Dataset.from_tensors(data)\n",
    "    dataset = dataset.map(trans, num_parallel_calls=4)\n",
    "    dataset = dataset.map(add_seq_cols, num_parallel_calls=4)\n",
    "    print('cols', cols)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.padded_batch(5, OrderedDict(zip(cols, ([], [], [], [None], [], [None], [], []))))\n",
    "    inputs = dataset.make_one_shot_iterator().get_next()\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            _, = sess.run([inputs])\n",
    "            # print( sess.run(inputs) )\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_datasets(fpath_ary, schema, n_batch=128, n_epoch=1):\n",
    "    def to_dense(sp):\n",
    "        dense = tf.sparse_to_dense(sp.indices, sp.dense_shape, sp.values, '')\n",
    "        return tf.reshape(tf.to_int32(tf.string_to_number(dense)), [-1])\n",
    "\n",
    "    def to_sparse(dense):\n",
    "        idx = tf.where(tf.not_equal(dense, 0))\n",
    "        return tf.SparseTensor(indices=idx, dense_shape=dense.get_shape(), values=tf.gather_nd(dense, idx))\n",
    "\n",
    "    def parse_csv(value):\n",
    "        data = tf.decode_csv(value, record_defaults=defaults)\n",
    "        features = OrderedDict(zip(cols, data))\n",
    "        multi_cols = df_conf.query(\"{} == '{}' and {} == True\".format(schema.M_DTYPE, schema.CATG, schema.IS_MULTI)).id.values\n",
    "        for col in multi_cols:\n",
    "            features[col] = tf.string_split([features[col]], ',')\n",
    "            features[col] = to_dense(features[col])\n",
    "            # features['{}_lens'.format(col)] = tf.size(features[col])\n",
    "        return features \n",
    "    \n",
    "    df_conf = schema.df_conf_.query('{}.notnull()'.format(schema.TYPE))\n",
    "    cols = schema.cols\n",
    "    defaults = []\n",
    "    for _, r in df_conf.iterrows():\n",
    "        if r[schema.M_DTYPE] == schema.CATG:\n",
    "            defaults.append([''] if r[schema.IS_MULTI] else [0])\n",
    "        else:\n",
    "            defaults.append([])\n",
    "    dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=4)\n",
    "    has_multi = (df_conf[schema.M_DTYPE] == schema.CATG) & (df_conf[schema.IS_MULTI] == True)\n",
    "    if sum(has_multi):\n",
    "        multi_cols = df_conf[has_multi].id.values\n",
    "        dataset = dataset.padded_batch(n_batch, OrderedDict( zip(cols, tuple([None] if e else [] for e in has_multi))) )\n",
    "    else:\n",
    "        dataset = dataset.batch(n_batch)\n",
    "    dataset = dataset.shuffle(n_batch * 10, seed=seed).repeat(n_epoch)\n",
    "    features = dataset.make_one_shot_iterator().get_next()\n",
    "    return features, features.pop(schema.label[0])\n",
    "                                \n",
    "# tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    inputs = make_datasets(['./movielens.tr'], loader.schema, n_batch=30)\n",
    "    query_lens = tf.sequence_mask([1, 2, 3])\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            _, = sess.run([inputs])\n",
    "            # print( sess.run(inputs) )\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Columns with tf.feature_column.input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.Series(minmax_scale(np.random.normal(0, 1, size=1000)))\n",
    "a.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    user_id = tf.feature_column.categorical_column_with_hash_bucket('user_id', hash_bucket_size=1000, dtype=tf.int32)\n",
    "    user_id = tf.feature_column.embedding_column(user_id, dimension=8)\n",
    "    avg_rating = tf.feature_column.numeric_column('avg_rating')\n",
    "    columns = [user_id, avg_rating]\n",
    "    \n",
    "    def make_datasets(fpath_ary):\n",
    "        cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "        defaults = [[0], [''], [''], [], [], [0], []]\n",
    "\n",
    "        def parse_csv(value):\n",
    "            data = tf.decode_csv(value, record_defaults=defaults)\n",
    "            features = OrderedDict(zip(cols, data))\n",
    "            # print(features)\n",
    "            return features\n",
    "        \n",
    "        dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "        dataset = (dataset.map(parse_csv, num_parallel_calls=4)\n",
    "                          .batch(3)\n",
    "                          # .padded_batch(3, OrderedDict(zip(cols, ([], [None], [None], [], [], [], []))))\n",
    "                          .shuffle(10, seed=seed)\n",
    "                          .repeat(1)\n",
    "                  )\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    inputs = make_datasets(['./te_processed.batch.csv'])\n",
    "    inputs = tf.feature_column.input_layer(inputs, columns)\n",
    "    # features = tf.parse_example(serialized_example, features=tf.feature_column.make_parse_example_spec(columns))\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Make Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "is_multi = [False, True, True, False, False, False, False]\n",
    "pd_dtypes = [int, str, str, float, float, int, float]\n",
    "types = ['int64_list', 'int64_list', 'int64_list', 'float_list', 'float_list', 'int64_list', 'float_list']\n",
    "tf_types = [tf.int64, tf.int64, tf.int64, tf.float32, tf.float32, tf.int64, tf.float32]\n",
    "def persist_example(fpath, tfpath):\n",
    "    with tf.python_io.TFRecordWriter(tfpath) as w:\n",
    "        for chunk in pd.read_csv(fpath, names=cols, dtype=dict(zip(cols, pd_dtypes)), chunksize=1000):\n",
    "            chunk['query_movie_ids'] = chunk.query_movie_ids.map(lambda r: map(int, r.split(',')))\n",
    "            chunk['genres'] = chunk.genres.map(lambda r: map(int, r.split(',')))\n",
    "            \n",
    "            for idx, r in chunk.iterrows():\n",
    "                ex = tf.train.Example()\n",
    "                for multi, col, tpe in zip(is_multi, cols, types):\n",
    "                    val = r[col]\n",
    "                    # ex.features.feature[col].int64_list or float_list or bytes_list\n",
    "                    feat_type = getattr(ex.features.feature[col], tpe)\n",
    "                    # extend function for multivalent columns, otherwise append\n",
    "                    append_or_extend = 'append' if not multi else 'extend'                    \n",
    "                    getattr(feat_type.value, append_or_extend)(val)\n",
    "                w.write(ex.SerializePartialToString())\n",
    "\n",
    "persist_example('./te_processed.csv', './data.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_example(ser_example):\n",
    "    # queue = tf.train.string_input_producer([fpath], num_epochs=1)\n",
    "    # _, ser_example = tf.TFRecordReader().read(queue)\n",
    "    # ser_example = tf.train.batch([ser_example], batch_size=10)\n",
    "    ctx_features = {col: tf.FixedLenFeature([], tf_tpe)\n",
    "                    for col, tf_tpe in zip(cols, tf_types) if col not in ('query_movie_ids', 'genres')}\n",
    "    seq_features = {col: tf.FixedLenSequenceFeature([], tf_tpe) \n",
    "                    for col, tf_tpe in [('query_movie_ids', tf.int64), ('genres', tf.int64)]}\n",
    "    context_dict, sequence_dict = tf.parse_single_sequence_example(ser_example, \n",
    "                                                                   context_features=ctx_features, \n",
    "                                                                   sequence_features=seq_features)\n",
    "    # for col, tpe in zip(cols, tf_types):\n",
    "    #     val = feature_dict[col]\n",
    "    #     feature_dict[col] = tf.sparse_to_dense(val.indices, val.dense_shape, val.values, name=col)\n",
    "    feature_dict = {}\n",
    "    feature_dict.update(context_dict)\n",
    "    feature_dict.update(sequence_dict)\n",
    "    ret = OrderedDict()\n",
    "    for c in cols:\n",
    "        ret[c] = feature_dict[c]\n",
    "    return tuple(ret.values())\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    dataset = tf.data.TFRecordDataset(['./data.tfrecord'])\n",
    "    dataset = dataset.map(decode_example).padded_batch(10, padded_shapes=([], [None], [None], [], [], [], []))\n",
    "    # dataset = dataset.batch(3)\n",
    "    iters = dataset.make_one_shot_iterator()\n",
    "    r = iters.get_next()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        print( sess.run(r) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional parse_example\n",
    "1. tf.train.Coordinator + tf.train.start_queue_runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import sparse_tensor\n",
    "import re\n",
    "\n",
    "def to_sparse(dense):\n",
    "    idx = tf.where(tf.not_equal(dense, 0))\n",
    "    return tf.SparseTensor(idx, tf.gather_nd(dense, idx), dense.get_shape())\n",
    "\n",
    "def make_example(val):\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature = {\n",
    "            'query_movie_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=val)),\n",
    "            'genres': tf.train.Feature(int64_list=tf.train.Int64List(value=val))\n",
    "        }\n",
    "    ))\n",
    "    return example\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    filename = \"tmp.tfrecords\"\n",
    "    if not os.path.exists(filename):\n",
    "        # os.remove(filename)\n",
    "        writer = tf.python_io.TFRecordWriter(filename)\n",
    "        with writer:\n",
    "            for idx, r in teProcessed.head().iterrows():\n",
    "                for col in ('query_movie_ids', 'genres'):\n",
    "                    val = list(map(int, re.split(',\\s*', r[col])))\n",
    "                    ex = make_example(val)\n",
    "                    writer.write(ex.SerializeToString())\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    filename_queue = tf.train.string_input_producer([\"tmp.tfrecords\"], num_epochs=1)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    batch = tf.train.batch(tensors=[serialized_example], batch_size=1)\n",
    "    features = {\n",
    "        'query_movie_ids': tf.VarLenFeature(tf.int64),\n",
    "        'genres': tf.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    data = tf.parse_example(batch, features)\n",
    "    query_movie_ids = data['query_movie_ids']\n",
    "    embbedding = tf.Variable(tf.glorot_uniform_initializer()([9125]), dtype=tf.float32)\n",
    "    print(query_movie_ids.dense_shape)\n",
    "    # r = tf.layers.dense(query_movie_ids, 10)\n",
    "    # emb_query = tf.nn.embedding_lookup_sparse([embbedding], query_movie_ids, None, combiner='sqrtn')\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        try:\n",
    "            print(sess.run(data))\n",
    "            pass\n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            coord.request_stop(e)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    labels = tf.constant(np.ones([10, 8]))\n",
    "    pred = tf.concat([tf.Variable(tf.ones(shape=[1, 8]), trainable=False), tf.Variable(tf.truncated_normal([9, 8]))], 0)\n",
    "    loss = tf.losses.mean_squared_error(predictions=pred, labels=labels)\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(pred.eval())\n",
    "        for i in range(1000):\n",
    "            sess.run([train_op])\n",
    "        print()\n",
    "        print(pred.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.zeros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
