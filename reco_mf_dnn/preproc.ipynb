{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, re, codecs, seaborn as sns, json, time, csv, datetime as dt\n",
    "import pickle, collections, random, math, numbers, scipy.sparse as sp, matplotlib.pyplot as plt, scipy.sparse as sp\n",
    "\n",
    "def reload(mName):\n",
    "    import importlib\n",
    "    if mName in sys.modules:\n",
    "        del sys.modules[mName]\n",
    "    return importlib.import_module(mName)\n",
    "\n",
    "\n",
    "from collections import deque, defaultdict, OrderedDict\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, minmax_scale\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# classpath\n",
    "ctx = os.path.abspath('..')\n",
    "cps = [ctx]\n",
    "_ = [sys.path.insert(0, cp) for cp in cps if cp not in sys.path]\n",
    "\n",
    "# data path\n",
    "datapath = '/'.join([ctx, 'data'])\n",
    "\n",
    "seed = 88\n",
    "utils = reload('utils.utils')\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.partial_fit(np.array([1, 2, 3])[:, np.newaxis]).partial_fit(np.array([4, 5])[:, np.newaxis])\n",
    "scaler.transform(np.array([1, 5])[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "teProcessed = pd.read_csv('./te_processed.csv', names=headers)\n",
    "# teProcessed['query_movie_ids'] = teProcessed.query_movie_ids.str.replace('\\[(.+)\\]', '\\\\1')\n",
    "# teProcessed['genres'] = teProcessed.genres.str.replace('\\[(.+)\\]', '\\\\1')\n",
    "teProcessed.head() # .to_csv('./te_processed.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set([batch[batch.composer.str.contains('\\|', na=False)].iloc[0].lyricist])\n",
    "mapper = utils.PartialMapper(10000, keep_order=False).partial_fit()\n",
    "mapper.inverse_transform(mapper.transform(batch.lyricist))[:10]\n",
    "mapper.enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.decode_csv + tf.data.TextLineDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "ratings = pd.read_csv(\"{}/ml-latest-small/ratings.csv\".format(datapath))\n",
    "ratings['timestamp'] = ratings.timestamp.map(dt.datetime.fromtimestamp).map(str)\n",
    "ratings['ori_rating'] = ratings['rating']\n",
    "ratings['rating'] = (ratings.rating >= 4).astype(int)\n",
    "tr, te = utils.split_ratings(ratings)\n",
    "\n",
    "movies = pd.read_csv(\"{}/ml-latest-small/movies.csv\".format(datapath))\n",
    "avg_rt = ratings.groupby(\"movieId\", as_index=False).ori_rating.mean().rename(index=str, columns={'ori_rating': 'avg_rating'})\n",
    "movies = movies.merge(avg_rt, how='left', on='movieId')\n",
    "# movies.avg_rating.fillna(ratings.rating.mean())\n",
    "movies[\"year\"] = movies.title.str.findall(\"\\(\\s*(\\d+)\\s*\\)\").map(lambda lst: int(lst[-1]) if len(lst) else None)\n",
    "# movies[\"year\"] = minmax_scale(movies.year.fillna(movies.year.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1953,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>2009-12-14 10:53:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.021739</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>2009-12-14 10:53:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>3.478723</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2105</td>\n",
       "      <td>2009-12-14 10:52:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,1029,1061,1129,1263,1287,1293,1...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2009-12-14 10:52:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,31,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Animation|Children|Drama|Musical</td>\n",
       "      <td>3.702381</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1029</td>\n",
       "      <td>2009-12-14 10:52:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    query_movie_ids  \\\n",
       "0        1  1953,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "1        1  1172,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "2        1  1172,1953,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "3        1  1172,1953,2105,1029,1061,1129,1263,1287,1293,1...   \n",
       "4        1  1172,1953,2105,31,1061,1129,1263,1287,1293,133...   \n",
       "\n",
       "                             genres  avg_rating    year  candidate_movie_id  \\\n",
       "0                             Drama    4.260870  1989.0                1172   \n",
       "1             Action|Crime|Thriller    4.021739  1971.0                1953   \n",
       "2           Action|Adventure|Sci-Fi    3.478723  1982.0                2105   \n",
       "3                             Drama    3.178571  1995.0                  31   \n",
       "4  Animation|Children|Drama|Musical    3.702381  1941.0                1029   \n",
       "\n",
       "             timestamp  rating  \n",
       "0  2009-12-14 10:53:25       1  \n",
       "1  2009-12-14 10:53:11       1  \n",
       "2  2009-12-14 10:52:19       1  \n",
       "3  2009-12-14 10:52:24       0  \n",
       "4  2009-12-14 10:52:59       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(data, movie_trans, train_hist=None, is_train=True):\n",
    "    queue = []\n",
    "    data = data.merge(movie_trans, how=\"left\", on=\"movieId\")\n",
    "    columns=[\"user_id\", \"query_movie_ids\",\n",
    "             \"genres\", \"avg_rating\", \"year\", \"candidate_movie_id\",\n",
    "             \"timestamp\",\n",
    "             \"rating\"]\n",
    "    \n",
    "    list2str = lambda lst: ','.join(map(str, lst))\n",
    "    for u, df in data.groupby(\"userId\"):\n",
    "        df = df.sort_values(\"rating\", ascending=False)\n",
    "        if not is_train:\n",
    "            user_movies_hist = train_hist.query(\"userId == {}\".format(u)).movieId\n",
    "        for i, (_, r) in enumerate(df.iterrows()):\n",
    "            if is_train:\n",
    "                query_hist = df.movieId[:i].tolist() + df.movieId[i + 1:].tolist()\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "            else:\n",
    "                all_hist = set(user_movies_hist.tolist())\n",
    "                query_hist = list(all_hist - set([int(r.movieId)]))\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "    return pd.DataFrame(queue, columns=columns)\n",
    "    \n",
    "tr_merged = preprocess(tr, movies)\n",
    "tr_merged.to_csv('./tr_movielens.csv', index=False, header=None)\n",
    "\n",
    "te_merged = preprocess(te, movies, tr, is_train=False)\n",
    "te_merged.to_csv('./te_movielens.csv', index=False, header=None)\n",
    "te_merged.head()\n",
    "# 合併成一個檔案\n",
    "merged = pd.concat([tr_merged, te_merged], ignore_index=True)\n",
    "merged.to_csv('./merged_movielens.csv', index=False, header=None)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 1953, 1172, 1029, 2105, 31]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils = reload('utils.utils')\n",
    "mapper = utils.PartialMapper(padding_null=True).partial_fit( merged.head().candidate_movie_id )\n",
    "mapper.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\pandas\\core\\strings.py:1036: FutureWarning: split() requires a non-empty pattern match.\n",
      "  f = lambda x: regex.split(x, maxsplit=n)\n"
     ]
    }
   ],
   "source": [
    "# self.conf = OrderedDict(\n",
    "#     user = [{Schema.ID: 'query_movie_ids', Schema.DTYPE: 'str', Schema.MODEL_DTYPE: 'catg',\n",
    "#              Schema.N_UNIQUE: 9125, Schema.IS_MULTI: True, Schema.SEP: ','}],\n",
    "#     item = [{Schema.ID: 'genres', Schema.DTYPE: 'str', Schema.MODEL_DTYPE: 'catg', Schema.N_UNIQUE: 20, Schema.IS_MULTI: True, Schema.SEP: ','},\n",
    "#             {Schema.ID: 'avg_rating', Schema.DTYPE: 'float', Schema.MODEL_DTYPE: 'cont'},\n",
    "#             {Schema.ID: 'year', Schema.DTYPE: 'float', Schema.MODEL_DTYPE: 'cont'},\n",
    "#             {Schema.ID: 'candidate_movie_id', Schema.TYPE: 'catg', Schema.N_UNIQUE: 9125}],\n",
    "#     label = [{Schema.ID: 'rating', Schema.MODEL_DTYPE: 'catg'}]\n",
    "# )\n",
    "utils = reload('utils.utils')\n",
    "reco = reload('reco_mf_dnn.reco_mf_dnn_flex_shema')\n",
    "json_conf = '''\n",
    "{\n",
    "    \"columns\": [{\"id\": \"user_id\", \"m_dtype\": \"catg\"},\n",
    "                {\"id\": \"query_movie_ids\", \"m_dtype\": \"catg\", \"is_multi\": true, \"n_unique\": 9125, \"sep\": \",\"},\n",
    "                {\"id\": \"genres\", \"m_dtype\": \"catg\", \"is_multi\": true, \"sep\": \"|\", \"n_unique\": 20},\n",
    "                {\"id\": \"avg_rating\", \"m_dtype\": \"cont\"},\n",
    "                {\"id\": \"year\", \"m_dtype\": \"cont\"},\n",
    "                {\"id\": \"candidate_movie_id\", \"m_dtype\": \"catg\", \"n_unique\": 9125},\n",
    "                {\"id\": \"timestamp\", \"m_dtype\": \"datetime\", \"date_format\": \"%Y-%m-%d %H:%M:%S\"},\n",
    "                {\"id\": \"rating\", \"m_dtype\": \"catg\", \"n_unique\": 2}],\n",
    "    \"label\": [\"rating\"],\n",
    "    \"user\": [\"query_movie_ids\", \"timestamp\"],\n",
    "    \"item\": [\"genres\", \"avg_rating\", \"year\", \"candidate_movie_id\"]\n",
    "}\n",
    "'''.strip()\n",
    "schema = reco.Schema(json_conf, ['./merged_movielens.csv'])\n",
    "# schema.df_conf_\n",
    "# schema.col_states['query_movie_ids'].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_format</th>\n",
       "      <th>m_dtype</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>is_multi</th>\n",
       "      <th>sep</th>\n",
       "      <th>aux</th>\n",
       "      <th>type</th>\n",
       "      <th>col_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query_movie_ids</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>9125</td>\n",
       "      <td>True</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>{\"classes_\": [null, \"527\", \"52\", \"2028\", \"31\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>|</td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "      <td>{\"classes_\": [null, \"Drama|Romance|War|Western...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_rating</td>\n",
       "      <td></td>\n",
       "      <td>cont</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "      <td>{\"min_\": 2.2051282051282053, \"cumsum_\": 360.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year</td>\n",
       "      <td></td>\n",
       "      <td>cont</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "      <td>{\"min_\": 1941.0, \"cumsum_\": 199205.0, \"max_\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>candidate_movie_id</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>9125</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "      <td>{\"classes_\": [null, \"527\", \"52\", \"2028\", \"31\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>%Y-%m-%d %H:%M:%S</td>\n",
       "      <td>datetime</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>{\"min_\": 835355395.0, \"cumsum_\": 104787784765....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rating</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>label</td>\n",
       "      <td>{\"classes_\": [null, \"1\", \"0\"]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        date_format   m_dtype  n_unique  is_multi sep    aux   type  \\\n",
       "0             user_id                         catg         0     False      False          \n",
       "1     query_movie_ids                         catg      9125      True   ,  False   user   \n",
       "2              genres                         catg        20      True   |  False   item   \n",
       "3          avg_rating                         cont         0     False      False   item   \n",
       "4                year                         cont         0     False      False   item   \n",
       "5  candidate_movie_id                         catg      9125     False      False   item   \n",
       "6           timestamp  %Y-%m-%d %H:%M:%S  datetime         0     False      False   user   \n",
       "7              rating                         catg         2     False      False  label   \n",
       "\n",
       "                                           col_state  \n",
       "0                                                     \n",
       "1  {\"classes_\": [null, \"527\", \"52\", \"2028\", \"31\",...  \n",
       "2  {\"classes_\": [null, \"Drama|Romance|War|Western...  \n",
       "3  {\"min_\": 2.2051282051282053, \"cumsum_\": 360.27...  \n",
       "4  {\"min_\": 1941.0, \"cumsum_\": 199205.0, \"max_\": ...  \n",
       "5  {\"classes_\": [null, \"527\", \"52\", \"2028\", \"31\",...  \n",
       "6  {\"min_\": 835355395.0, \"cumsum_\": 104787784765....  \n",
       "7                     {\"classes_\": [null, \"1\", \"0\"]}  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.df_conf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aux': False, 'type': '', 'm_dtype': 'catg', 'id': 'user_id', 'sep': '', 'n_unique': 0, 'is_multi': False, 'col_state': '', 'date_format': ''}\n",
      "{'aux': False, 'type': 'user', 'm_dtype': 'catg', 'id': 'query_movie_ids', 'sep': ',', 'n_unique': 9125, 'is_multi': True, 'col_state': '{\"classes_\": [null, \"527\", \"52\", \"2028\", \"31\", \"317\", \"1172\", \"2841\", \"186\", \"339\", \"592\", \"356\", \"165\", \"318\", \"47\", \"222\", \"349\", \"208\", \"265\", \"778\", \"1271\", \"1263\", \"273\", \"247\", \"593\", \"474\", \"1293\", \"468\", \"2513\", \"367\", \"1129\", \"377\", \"153\", \"10\", \"235\", \"168\", \"2694\", \"150\", \"1884\", \"371\", \"350\", \"410\", \"370\", \"357\", \"144\", \"2762\", \"267\", \"292\", \"2959\", \"372\", \"1378\", \"2105\", \"39\", \"261\", \"1405\", \"319\", \"1287\", \"2858\", \"1580\", \"253\", \"2318\", \"2716\", \"1029\", \"296\", \"595\", \"1343\", \"1371\", \"1061\", \"60\", \"588\", \"50\", \"161\", \"364\", \"355\", \"866\", \"1197\", \"1235\", \"382\", \"1210\", \"248\", \"185\", \"457\", \"272\", \"62\", \"266\", \"223\", \"300\", \"110\", \"480\", \"454\", \"405\", \"1953\", \"1339\", \"17\", \"736\", \"225\", \"314\", \"2702\", \"1721\"]}', 'date_format': ''}\n"
     ]
    }
   ],
   "source": [
    "lst = schema.df_conf_.to_dict('records')\n",
    "for i, e in enumerate(lst, 1):\n",
    "    print(e)\n",
    "    if i >= 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aux': False,\n",
       "  'col_state': '',\n",
       "  'date_format': '',\n",
       "  'id': 'user_id',\n",
       "  'is_multi': False,\n",
       "  'm_dtype': 'catg',\n",
       "  'n_unique': 0,\n",
       "  'sep': '',\n",
       "  'type': ''},\n",
       " {'aux': False,\n",
       "  'col_state': '{\"classes_\": [null, \"527\", \"52\", \"2028\", \"31\", \"317\", \"1172\", \"2841\", \"186\", \"339\", \"592\", \"356\", \"165\", \"318\", \"47\", \"222\", \"349\", \"208\", \"265\", \"778\", \"1271\", \"1263\", \"273\", \"247\", \"593\", \"474\", \"1293\", \"468\", \"2513\", \"367\", \"1129\", \"377\", \"153\", \"10\", \"235\", \"168\", \"2694\", \"150\", \"1884\", \"371\", \"350\", \"410\", \"370\", \"357\", \"144\", \"2762\", \"267\", \"292\", \"2959\", \"372\", \"1378\", \"2105\", \"39\", \"261\", \"1405\", \"319\", \"1287\", \"2858\", \"1580\", \"253\", \"2318\", \"2716\", \"1029\", \"296\", \"595\", \"1343\", \"1371\", \"1061\", \"60\", \"588\", \"50\", \"161\", \"364\", \"355\", \"866\", \"1197\", \"1235\", \"382\", \"1210\", \"248\", \"185\", \"457\", \"272\", \"62\", \"266\", \"223\", \"300\", \"110\", \"480\", \"454\", \"405\", \"1953\", \"1339\", \"17\", \"736\", \"225\", \"314\", \"2702\", \"1721\"]}',\n",
       "  'date_format': '',\n",
       "  'id': 'query_movie_ids',\n",
       "  'is_multi': True,\n",
       "  'm_dtype': 'catg',\n",
       "  'n_unique': 9125,\n",
       "  'sep': ',',\n",
       "  'type': 'user'},\n",
       " {'aux': False,\n",
       "  'col_state': '{\"classes_\": [null, \"Drama|Romance|War|Western\", \"Adventure|Drama|IMAX\", \"Crime|Drama|Romance|Thriller\", \"Drama|Mystery|Thriller\", \"Comedy|Drama|Romance|War\", \"Comedy|Crime|Drama|Thriller\", \"Crime|Drama\", \"Animation|Children|Drama|Musical\", \"Action|Crime|Thriller\", \"Drama|Thriller\", \"Action|Adventure|Comedy|Crime\", \"Action|Adventure|Thriller\", \"Comedy|Drama|Thriller\", \"Adventure|Comedy|Drama\", \"Drama|War\", \"Action|Adventure|Drama\", \"Children|Drama|Fantasy|Mystery\", \"Action|Adventure|Sci-Fi\", \"Comedy|Drama|Romance\", \"Adventure|Animation|Children|Drama|Musical|IMAX\", \"Children|Comedy|Fantasy\", \"Action|Drama|Romance\", \"Comedy|Drama|Fantasy\", \"Horror|Mystery|Thriller\", \"Action|Comedy\", \"Adventure|Animation|Children|Comedy|Musical\", \"Action|Drama|Sci-Fi|Thriller\", \"Comedy|Romance\", \"Action|Adventure|Comedy|Fantasy|Romance\", \"Thriller\", \"Adventure|Sci-Fi\", \"Drama|Horror|Mystery\", \"Horror\", \"Crime|Horror|Thriller\", \"Action|Crime|Drama|Thriller\", \"Comedy\", \"Comedy|Crime|Drama\", \"Action|Thriller\", \"Drama|Horror\", \"Action|Comedy|Sci-Fi\", \"Drama\", \"Action|Adventure|Sci-Fi|Thriller\", \"Action|Comedy|Crime|Fantasy\", \"Drama|Thriller|War\", \"Adventure|Animation|Comedy|Crime\", \"Animation|Children|Fantasy|Musical|Romance|IMAX\", \"Fantasy|Horror|Romance|Thriller\", \"Action|Drama|War\", \"Action|Fantasy\", \"Action|Comedy|Western\", \"Drama|Horror|Sci-Fi\", \"Drama|Fantasy|Romance\", \"Drama|Horror|Romance|Thriller\", \"Mystery|Thriller\", \"Action|Romance|Thriller\", \"Comedy|Drama\", \"Drama|Romance\", \"Crime|Mystery|Thriller\"]}',\n",
       "  'date_format': '',\n",
       "  'id': 'genres',\n",
       "  'is_multi': True,\n",
       "  'm_dtype': 'catg',\n",
       "  'n_unique': 20,\n",
       "  'sep': '|',\n",
       "  'type': 'item'},\n",
       " {'aux': False,\n",
       "  'col_state': '{\"min_\": 2.2051282051282053, \"cumsum_\": 360.27095737672255, \"max_\": 4.487138263665594, \"n_total_\": 100}',\n",
       "  'date_format': '',\n",
       "  'id': 'avg_rating',\n",
       "  'is_multi': False,\n",
       "  'm_dtype': 'cont',\n",
       "  'n_unique': 0,\n",
       "  'sep': '',\n",
       "  'type': 'item'},\n",
       " {'aux': False,\n",
       "  'col_state': '{\"min_\": 1941.0, \"cumsum_\": 199205.0, \"max_\": 1999.0, \"n_total_\": 100}',\n",
       "  'date_format': '',\n",
       "  'id': 'year',\n",
       "  'is_multi': False,\n",
       "  'm_dtype': 'cont',\n",
       "  'n_unique': 0,\n",
       "  'sep': '',\n",
       "  'type': 'item'},\n",
       " {'aux': False,\n",
       "  'col_state': '{\"classes_\": [null, \"527\", \"52\", \"2028\", \"31\", \"317\", \"1172\", \"2841\", \"186\", \"339\", \"592\", \"356\", \"165\", \"318\", \"47\", \"222\", \"349\", \"208\", \"265\", \"778\", \"1271\", \"1263\", \"273\", \"247\", \"593\", \"474\", \"1293\", \"468\", \"2513\", \"367\", \"1129\", \"377\", \"153\", \"10\", \"235\", \"168\", \"2694\", \"150\", \"1884\", \"371\", \"350\", \"410\", \"370\", \"357\", \"144\", \"2762\", \"267\", \"292\", \"2959\", \"372\", \"1378\", \"2105\", \"39\", \"261\", \"1405\", \"319\", \"1287\", \"2858\", \"1580\", \"253\", \"2318\", \"2716\", \"1029\", \"296\", \"595\", \"1343\", \"1371\", \"1061\", \"588\", \"50\", \"161\", \"364\", \"355\", \"866\", \"1197\", \"1235\", \"382\", \"1210\", \"248\", \"185\", \"457\", \"272\", \"62\", \"266\", \"223\", \"300\", \"110\", \"480\", \"454\", \"405\", \"1953\", \"1339\", \"17\", \"225\", \"314\", \"2702\", \"1721\"]}',\n",
       "  'date_format': '',\n",
       "  'id': 'candidate_movie_id',\n",
       "  'is_multi': False,\n",
       "  'm_dtype': 'catg',\n",
       "  'n_unique': 9125,\n",
       "  'sep': '',\n",
       "  'type': 'item'},\n",
       " {'aux': False,\n",
       "  'col_state': '{\"min_\": 835355395.0, \"cumsum_\": 104787784765.0, \"max_\": 1298932770.0, \"n_total_\": 100}',\n",
       "  'date_format': '%Y-%m-%d %H:%M:%S',\n",
       "  'id': 'timestamp',\n",
       "  'is_multi': False,\n",
       "  'm_dtype': 'datetime',\n",
       "  'n_unique': 0,\n",
       "  'sep': '',\n",
       "  'type': 'user'},\n",
       " {'aux': False,\n",
       "  'col_state': '{\"classes_\": [null, \"1\", \"0\"]}',\n",
       "  'date_format': '',\n",
       "  'id': 'rating',\n",
       "  'is_multi': False,\n",
       "  'm_dtype': 'catg',\n",
       "  'n_unique': 2,\n",
       "  'sep': '',\n",
       "  'type': 'label'}]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(schema.df_conf_.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([80.])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils = reload('utils.utils')\n",
    "mapper = utils.NumericMapper()\n",
    "mapper.partial_fit([0, 80, None])\n",
    "print( mapper.mean )\n",
    "mapper.transform([1, 2, 3]) # array([0.0125, 0.025 , 0.0375])\n",
    "\n",
    "mapper.scaler.data_max_\n",
    "# mapper = utils.CatgMapper(padding_null=True)\n",
    "# mapper.partial_fit(['1', 'xxx', 'ooo'])\n",
    "# mapper.inverse_transform(mapper.transform(['xxx', '1', None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1953,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>2009-12-14 10:53:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.021739</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>2009-12-14 10:53:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>3.478723</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2105</td>\n",
       "      <td>2009-12-14 10:52:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,1029,1061,1129,1263,1287,1293,1...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2009-12-14 10:52:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,31,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Animation|Children|Drama|Musical</td>\n",
       "      <td>3.702381</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1029</td>\n",
       "      <td>2009-12-14 10:52:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    query_movie_ids                            genres  \\\n",
       "0        1  1953,2105,31,1029,1061,1129,1263,1287,1293,133...                             Drama   \n",
       "1        1  1172,2105,31,1029,1061,1129,1263,1287,1293,133...             Action|Crime|Thriller   \n",
       "2        1  1172,1953,31,1029,1061,1129,1263,1287,1293,133...           Action|Adventure|Sci-Fi   \n",
       "3        1  1172,1953,2105,1029,1061,1129,1263,1287,1293,1...                             Drama   \n",
       "4        1  1172,1953,2105,31,1061,1129,1263,1287,1293,133...  Animation|Children|Drama|Musical   \n",
       "\n",
       "   avg_rating    year  candidate_movie_id            timestamp  rating  \n",
       "0    4.260870  1989.0                1172  2009-12-14 10:53:25       1  \n",
       "1    4.021739  1971.0                1953  2009-12-14 10:53:11       1  \n",
       "2    3.478723  1982.0                2105  2009-12-14 10:52:19       1  \n",
       "3    3.178571  1995.0                  31  2009-12-14 10:52:24       0  \n",
       "4    3.702381  1941.0                1029  2009-12-14 10:52:59       0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "merged = pd.read_csv('./merged_movielens.csv', names=tr_merged.columns)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def make_datasets(fpath_ary):\n",
    "    cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "    defaults = [[0], [''], [''], [], [], [0], []]\n",
    "\n",
    "    def to_dense(sp):\n",
    "        dense = tf.sparse_to_dense(sp.indices, sp.dense_shape, sp.values, '')\n",
    "        return tf.reshape(tf.to_int32(tf.string_to_number(dense)), [-1])\n",
    "\n",
    "    def to_sparse(dense):\n",
    "        idx = tf.where(tf.not_equal(dense, 0))\n",
    "        return tf.SparseTensor(indices=idx, dense_shape=dense.get_shape(), values=tf.gather_nd(dense, idx))\n",
    "\n",
    "    def parse_csv(value):\n",
    "        data = tf.decode_csv(value, record_defaults=defaults)\n",
    "        features = OrderedDict(zip(cols, data))\n",
    "        for col in ('query_movie_ids', 'genres'):\n",
    "            features[col] = tf.string_split([features[col]], ',')\n",
    "            features[col] = to_sparse(to_dense(features[col]))\n",
    "        return features \n",
    "\n",
    "    dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "    dataset = (dataset.map(parse_csv, num_parallel_calls=4)\n",
    "                      .padded_batch(3, OrderedDict(zip(cols, ([], [None], [None], [], [], [], []))))\n",
    "                      .shuffle(10, seed=seed)\n",
    "                      .repeat(2)\n",
    "              )\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    inputs = make_datasets(['./te_processed.batch.csv'])\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            print(sess.run(inputs)['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Columns with tf.feature_column.input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d40eac6f60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABjifwEt5/l8tchuzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d40eb49c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = pd.Series(minmax_scale(np.random.normal(0, 1, size=1000)))\n",
    "a.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    user_id = tf.feature_column.categorical_column_with_hash_bucket('user_id', hash_bucket_size=1000, dtype=tf.int32)\n",
    "    user_id = tf.feature_column.embedding_column(user_id, dimension=8)\n",
    "    avg_rating = tf.feature_column.numeric_column('avg_rating')\n",
    "    columns = [user_id, avg_rating]\n",
    "    \n",
    "    def make_datasets(fpath_ary):\n",
    "        cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "        defaults = [[0], [''], [''], [], [], [0], []]\n",
    "\n",
    "        def parse_csv(value):\n",
    "            data = tf.decode_csv(value, record_defaults=defaults)\n",
    "            features = OrderedDict(zip(cols, data))\n",
    "            # print(features)\n",
    "            return features\n",
    "        \n",
    "        dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "        dataset = (dataset.map(parse_csv, num_parallel_calls=4)\n",
    "                          .batch(3)\n",
    "                          # .padded_batch(3, OrderedDict(zip(cols, ([], [None], [None], [], [], [], []))))\n",
    "                          .shuffle(10, seed=seed)\n",
    "                          .repeat(1)\n",
    "                  )\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    inputs = make_datasets(['./te_processed.batch.csv'])\n",
    "    inputs = tf.feature_column.input_layer(inputs, columns)\n",
    "    # features = tf.parse_example(serialized_example, features=tf.feature_column.make_parse_example_spec(columns))\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Make Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "is_multi = [False, True, True, False, False, False, False]\n",
    "pd_dtypes = [int, str, str, float, float, int, float]\n",
    "types = ['int64_list', 'int64_list', 'int64_list', 'float_list', 'float_list', 'int64_list', 'float_list']\n",
    "tf_types = [tf.int64, tf.int64, tf.int64, tf.float32, tf.float32, tf.int64, tf.float32]\n",
    "def persist_example(fpath, tfpath):\n",
    "    with tf.python_io.TFRecordWriter(tfpath) as w:\n",
    "        for chunk in pd.read_csv(fpath, names=cols, dtype=dict(zip(cols, pd_dtypes)), chunksize=1000):\n",
    "            chunk['query_movie_ids'] = chunk.query_movie_ids.map(lambda r: map(int, r.split(',')))\n",
    "            chunk['genres'] = chunk.genres.map(lambda r: map(int, r.split(',')))\n",
    "            \n",
    "            for idx, r in chunk.iterrows():\n",
    "                ex = tf.train.Example()\n",
    "                for multi, col, tpe in zip(is_multi, cols, types):\n",
    "                    val = r[col]\n",
    "                    # ex.features.feature[col].int64_list or float_list or bytes_list\n",
    "                    feat_type = getattr(ex.features.feature[col], tpe)\n",
    "                    # extend function for multivalent columns, otherwise append\n",
    "                    append_or_extend = 'append' if not multi else 'extend'                    \n",
    "                    getattr(feat_type.value, append_or_extend)(val)\n",
    "                w.write(ex.SerializePartialToString())\n",
    "\n",
    "persist_example('./te_processed.csv', './data.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_example(ser_example):\n",
    "    # queue = tf.train.string_input_producer([fpath], num_epochs=1)\n",
    "    # _, ser_example = tf.TFRecordReader().read(queue)\n",
    "    # ser_example = tf.train.batch([ser_example], batch_size=10)\n",
    "    ctx_features = {col: tf.FixedLenFeature([], tf_tpe)\n",
    "                    for col, tf_tpe in zip(cols, tf_types) if col not in ('query_movie_ids', 'genres')}\n",
    "    seq_features = {col: tf.FixedLenSequenceFeature([], tf_tpe) \n",
    "                    for col, tf_tpe in [('query_movie_ids', tf.int64), ('genres', tf.int64)]}\n",
    "    context_dict, sequence_dict = tf.parse_single_sequence_example(ser_example, \n",
    "                                                                   context_features=ctx_features, \n",
    "                                                                   sequence_features=seq_features)\n",
    "    # for col, tpe in zip(cols, tf_types):\n",
    "    #     val = feature_dict[col]\n",
    "    #     feature_dict[col] = tf.sparse_to_dense(val.indices, val.dense_shape, val.values, name=col)\n",
    "    feature_dict = {}\n",
    "    feature_dict.update(context_dict)\n",
    "    feature_dict.update(sequence_dict)\n",
    "    ret = OrderedDict()\n",
    "    for c in cols:\n",
    "        ret[c] = feature_dict[c]\n",
    "    return tuple(ret.values())\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    dataset = tf.data.TFRecordDataset(['./data.tfrecord'])\n",
    "    dataset = dataset.map(decode_example).padded_batch(10, padded_shapes=([], [None], [None], [], [], [], []))\n",
    "    # dataset = dataset.batch(3)\n",
    "    iters = dataset.make_one_shot_iterator()\n",
    "    r = iters.get_next()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        print( sess.run(r) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional parse_example\n",
    "1. tf.train.Coordinator + tf.train.start_queue_runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import sparse_tensor\n",
    "import re\n",
    "\n",
    "def to_sparse(dense):\n",
    "    idx = tf.where(tf.not_equal(dense, 0))\n",
    "    return tf.SparseTensor(idx, tf.gather_nd(dense, idx), dense.get_shape())\n",
    "\n",
    "def make_example(val):\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature = {\n",
    "            'query_movie_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=val)),\n",
    "            'genres': tf.train.Feature(int64_list=tf.train.Int64List(value=val))\n",
    "        }\n",
    "    ))\n",
    "    return example\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    filename = \"tmp.tfrecords\"\n",
    "    if not os.path.exists(filename):\n",
    "        # os.remove(filename)\n",
    "        writer = tf.python_io.TFRecordWriter(filename)\n",
    "        with writer:\n",
    "            for idx, r in teProcessed.head().iterrows():\n",
    "                for col in ('query_movie_ids', 'genres'):\n",
    "                    val = list(map(int, re.split(',\\s*', r[col])))\n",
    "                    ex = make_example(val)\n",
    "                    writer.write(ex.SerializeToString())\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    filename_queue = tf.train.string_input_producer([\"tmp.tfrecords\"], num_epochs=1)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    batch = tf.train.batch(tensors=[serialized_example], batch_size=1)\n",
    "    features = {\n",
    "        'query_movie_ids': tf.VarLenFeature(tf.int64),\n",
    "        'genres': tf.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    data = tf.parse_example(batch, features)\n",
    "    query_movie_ids = data['query_movie_ids']\n",
    "    embbedding = tf.Variable(tf.glorot_uniform_initializer()([9125]), dtype=tf.float32)\n",
    "    print(query_movie_ids.dense_shape)\n",
    "    # r = tf.layers.dense(query_movie_ids, 10)\n",
    "    # emb_query = tf.nn.embedding_lookup_sparse([embbedding], query_movie_ids, None, combiner='sqrtn')\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        try:\n",
    "            print(sess.run(data))\n",
    "            pass\n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            coord.request_stop(e)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    labels = tf.constant(np.ones([10, 8]))\n",
    "    pred = tf.concat([tf.Variable(tf.ones(shape=[1, 8]), trainable=False), tf.Variable(tf.truncated_normal([9, 8]))], 0)\n",
    "    loss = tf.losses.mean_squared_error(predictions=pred, labels=labels)\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(pred.eval())\n",
    "        for i in range(1000):\n",
    "            sess.run([train_op])\n",
    "        print()\n",
    "        print(pred.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.zeros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
