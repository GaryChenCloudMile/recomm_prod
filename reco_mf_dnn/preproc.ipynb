{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\anaconda3\\envs\\ml_dl\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, re, codecs, seaborn as sns, json, time, csv, datetime as dt\n",
    "import pickle, collections, random, math, numbers, scipy.sparse as sp, matplotlib.pyplot as plt, scipy.sparse as sp\n",
    "\n",
    "def reload(mName):\n",
    "    import importlib\n",
    "    if mName in sys.modules:\n",
    "        del sys.modules[mName]\n",
    "    return importlib.import_module(mName)\n",
    "\n",
    "\n",
    "from collections import deque, defaultdict, OrderedDict\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, minmax_scale\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# classpath\n",
    "ctx = os.path.abspath('..')\n",
    "cps = [ctx]\n",
    "_ = [sys.path.insert(0, cp) for cp in cps if cp not in sys.path]\n",
    "\n",
    "# data path\n",
    "datapath = '/'.join([ctx, 'data'])\n",
    "\n",
    "seed = 88\n",
    "utils = reload('utils.utils')\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "teProcessed = pd.read_csv('./te_processed.csv', names=headers)\n",
    "# teProcessed['query_movie_ids'] = teProcessed.query_movie_ids.str.replace('\\[(.+)\\]', '\\\\1')\n",
    "# teProcessed['genres'] = teProcessed.genres.str.replace('\\[(.+)\\]', '\\\\1')\n",
    "teProcessed.head() # .to_csv('./te_processed.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([batch[batch.composer.str.contains('\\|', na=False)].iloc[0].lyricist])\n",
    "mapper = utils.PartialMapper(10000, keep_order=False).partial_fit()\n",
    "mapper.inverse_transform(mapper.transform(batch.lyricist))[:10]\n",
    "mapper.enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.decode_csv + tf.data.TextLineDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "ratings = pd.read_csv(\"{}/ml-latest-small/ratings.csv\".format(datapath))\n",
    "ratings['timestamp'] = ratings.timestamp.map(dt.datetime.fromtimestamp).map(str)\n",
    "ratings['ori_rating'] = ratings['rating']\n",
    "ratings['rating'] = (ratings.rating >= 4).astype(int)\n",
    "tr, te = utils.split_ratings(ratings)\n",
    "\n",
    "movies = pd.read_csv(\"{}/ml-latest-small/movies.csv\".format(datapath))\n",
    "avg_rt = ratings.groupby(\"movieId\", as_index=False).ori_rating.mean().rename(index=str, columns={'ori_rating': 'avg_rating'})\n",
    "movies = movies.merge(avg_rt, how='left', on='movieId')\n",
    "# movies.avg_rating.fillna(ratings.rating.mean())\n",
    "movies[\"year\"] = movies.title.str.findall(\"\\(\\s*(\\d+)\\s*\\)\").map(lambda lst: int(lst[-1]) if len(lst) else None)\n",
    "# movies[\"year\"] = minmax_scale(movies.year.fillna(movies.year.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1953,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>2009-12-14 10:53:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.021739</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>2009-12-14 10:53:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>3.478723</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2105</td>\n",
       "      <td>2009-12-14 10:52:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,1029,1061,1129,1263,1287,1293,1...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2009-12-14 10:52:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,31,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Animation|Children|Drama|Musical</td>\n",
       "      <td>3.702381</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1029</td>\n",
       "      <td>2009-12-14 10:52:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    query_movie_ids  \\\n",
       "0        1  1953,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "1        1  1172,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "2        1  1172,1953,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "3        1  1172,1953,2105,1029,1061,1129,1263,1287,1293,1...   \n",
       "4        1  1172,1953,2105,31,1061,1129,1263,1287,1293,133...   \n",
       "\n",
       "                             genres  avg_rating    year  candidate_movie_id  \\\n",
       "0                             Drama    4.260870  1989.0                1172   \n",
       "1             Action|Crime|Thriller    4.021739  1971.0                1953   \n",
       "2           Action|Adventure|Sci-Fi    3.478723  1982.0                2105   \n",
       "3                             Drama    3.178571  1995.0                  31   \n",
       "4  Animation|Children|Drama|Musical    3.702381  1941.0                1029   \n",
       "\n",
       "             timestamp  rating  \n",
       "0  2009-12-14 10:53:25       1  \n",
       "1  2009-12-14 10:53:11       1  \n",
       "2  2009-12-14 10:52:19       1  \n",
       "3  2009-12-14 10:52:24       0  \n",
       "4  2009-12-14 10:52:59       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(data, movie_trans, train_hist=None, is_train=True):\n",
    "    queue = []\n",
    "    data = data.merge(movie_trans, how=\"left\", on=\"movieId\")\n",
    "    columns=[\"user_id\", \"query_movie_ids\",\n",
    "             \"genres\", \"avg_rating\", \"year\", \"candidate_movie_id\",\n",
    "             \"timestamp\",\n",
    "             \"rating\"]\n",
    "    \n",
    "    list2str = lambda lst: ','.join(map(str, lst))\n",
    "    for u, df in data.groupby(\"userId\"):\n",
    "        df = df.sort_values(\"rating\", ascending=False)\n",
    "        if not is_train:\n",
    "            user_movies_hist = train_hist.query(\"userId == {}\".format(u)).movieId\n",
    "        for i, (_, r) in enumerate(df.iterrows()):\n",
    "            if is_train:\n",
    "                query_hist = df.movieId[:i].tolist() + df.movieId[i + 1:].tolist()\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "            else:\n",
    "                all_hist = set(user_movies_hist.tolist())\n",
    "                query_hist = list(all_hist - set([int(r.movieId)]))\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "    return pd.DataFrame(queue, columns=columns)\n",
    "    \n",
    "tr_merged = preprocess(tr, movies)\n",
    "tr_merged.to_csv('./tr_movielens.csv', index=False, header=None)\n",
    "\n",
    "te_merged = preprocess(te, movies, tr, is_train=False)\n",
    "te_merged.to_csv('./te_movielens.csv', index=False, header=None)\n",
    "te_merged.head()\n",
    "# 合併成一個檔案\n",
    "merged = pd.concat([tr_merged, te_merged], ignore_index=True)\n",
    "merged.to_csv('./merged_movielens.csv', index=False, header=None)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 1953, 1172, 1029, 2105, 31]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils = reload('utils.utils')\n",
    "mapper = utils.PartialMapper(padding_null=True).partial_fit( merged.head().candidate_movie_id )\n",
    "mapper.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     query_movie_ids                            genres  \\\n",
      "1  1953,2105,31,1029,1061,1129,1263,1287,1293,133...                             Drama   \n",
      "1  1172,2105,31,1029,1061,1129,1263,1287,1293,133...             Action|Crime|Thriller   \n",
      "1  1172,1953,31,1029,1061,1129,1263,1287,1293,133...           Action|Adventure|Sci-Fi   \n",
      "1  1172,1953,2105,1029,1061,1129,1263,1287,1293,1...                             Drama   \n",
      "1  1172,1953,2105,31,1061,1129,1263,1287,1293,133...  Animation|Children|Drama|Musical   \n",
      "1  1172,1953,2105,31,1029,1129,1263,1287,1293,133...                          Thriller   \n",
      "1  1172,1953,2105,31,1029,1061,1263,1287,1293,133...  Action|Adventure|Sci-Fi|Thriller   \n",
      "1  1172,1953,2105,31,1029,1061,1129,1287,1293,133...                         Drama|War   \n",
      "1  1172,1953,2105,31,1029,1061,1129,1263,1293,133...            Action|Adventure|Drama   \n",
      "1  1172,1953,2105,31,1029,1061,1129,1263,1287,133...                             Drama   \n",
      "\n",
      "   avg_rating    year candidate_movie_id     timestamp rating  \n",
      "1    4.260870  1989.0               1172  1.260759e+09      1  \n",
      "1    4.021739  1971.0               1953  1.260759e+09      1  \n",
      "1    3.478723  1982.0               2105  1.260759e+09      1  \n",
      "1    3.178571  1995.0                 31  1.260759e+09      0  \n",
      "1    3.702381  1941.0               1029  1.260759e+09      0  \n",
      "1    3.545455  1996.0               1061  1.260759e+09      0  \n",
      "1    3.312500  1981.0               1129  1.260759e+09      0  \n",
      "1    3.864583  1978.0               1263  1.260759e+09      0  \n",
      "1    3.891304  1959.0               1287  1.260759e+09      0  \n",
      "1    3.978261  1982.0               1293  1.260759e+09      0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_format</th>\n",
       "      <th>m_dtype</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>is_multi</th>\n",
       "      <th>sep</th>\n",
       "      <th>aux</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_id</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>9125</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query_movie_ids</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>9125</td>\n",
       "      <td>True</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genres</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>|</td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_rating</td>\n",
       "      <td></td>\n",
       "      <td>cont</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year</td>\n",
       "      <td></td>\n",
       "      <td>cont</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>candidate_movie_id</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>9125</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>%Y-%m-%d %H:%M:%S</td>\n",
       "      <td>datetime</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rating</td>\n",
       "      <td></td>\n",
       "      <td>catg</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        date_format   m_dtype  n_unique  is_multi sep    aux   type\n",
       "0             user_id                         catg      9125      True      False       \n",
       "1     query_movie_ids                         catg      9125      True   ,  False   user\n",
       "2              genres                         catg        20      True   |  False   item\n",
       "3          avg_rating                         cont         0     False      False   item\n",
       "4                year                         cont         0     False      False   item\n",
       "5  candidate_movie_id                         catg      9125     False      False   item\n",
       "6           timestamp  %Y-%m-%d %H:%M:%S  datetime         0     False      False   user\n",
       "7              rating                         catg         2     False      False  label"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self.conf = OrderedDict(\n",
    "#     user = [{Schema.ID: 'query_movie_ids', Schema.DTYPE: 'str', Schema.MODEL_DTYPE: 'catg',\n",
    "#              Schema.N_UNIQUE: 9125, Schema.IS_MULTI: True, Schema.SEP: ','}],\n",
    "#     item = [{Schema.ID: 'genres', Schema.DTYPE: 'str', Schema.MODEL_DTYPE: 'catg', Schema.N_UNIQUE: 20, Schema.IS_MULTI: True, Schema.SEP: ','},\n",
    "#             {Schema.ID: 'avg_rating', Schema.DTYPE: 'float', Schema.MODEL_DTYPE: 'cont'},\n",
    "#             {Schema.ID: 'year', Schema.DTYPE: 'float', Schema.MODEL_DTYPE: 'cont'},\n",
    "#             {Schema.ID: 'candidate_movie_id', Schema.TYPE: 'catg', Schema.N_UNIQUE: 9125}],\n",
    "#     label = [{Schema.ID: 'rating', Schema.MODEL_DTYPE: 'catg'}]\n",
    "# )\n",
    "reco = reload('reco_mf_dnn.reco_mf_dnn_flex_shema')\n",
    "conf = '''\n",
    "{\n",
    "    \"columns\": [{\"id\": \"user_id\", \"m_dtype\": \"catg\", \"n_unique\": 9125, \"is_multi\": true},\n",
    "                {\"id\": \"query_movie_ids\", \"m_dtype\": \"catg\", \"is_multi\": true, \"n_unique\": 9125, \"sep\": \",\"},\n",
    "                {\"id\": \"genres\", \"m_dtype\": \"catg\", \"is_multi\": true, \"sep\": \"|\", \"n_unique\": 20},\n",
    "                {\"id\": \"avg_rating\", \"m_dtype\": \"cont\"},\n",
    "                {\"id\": \"year\", \"m_dtype\": \"cont\"},\n",
    "                {\"id\": \"candidate_movie_id\", \"m_dtype\": \"catg\", \"n_unique\": 9125},\n",
    "                {\"id\": \"timestamp\", \"m_dtype\": \"datetime\", \"date_format\": \"%Y-%m-%d %H:%M:%S\"},\n",
    "                {\"id\": \"rating\", \"m_dtype\": \"catg\", \"n_unique\": 2}],\n",
    "    \"label\": [\"rating\"],\n",
    "    \"user\": [\"query_movie_ids\", \"timestamp\"],\n",
    "    \"item\": [\"genres\", \"avg_rating\", \"year\", \"candidate_movie_id\"]\n",
    "}\n",
    "'''.strip()\n",
    "schema = reco.Schema(conf)\n",
    "schema.df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_datetime in module pandas.core.tools.datetimes:\n",
      "\n",
      "to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False, utc=None, box=True, format=None, exact=True, unit=None, infer_datetime_format=False, origin='unix')\n",
      "    Convert argument to datetime.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    arg : integer, float, string, datetime, list, tuple, 1-d array, Series\n",
      "    \n",
      "        .. versionadded: 0.18.1\n",
      "    \n",
      "           or DataFrame/dict-like\n",
      "    \n",
      "    errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
      "    \n",
      "        - If 'raise', then invalid parsing will raise an exception\n",
      "        - If 'coerce', then invalid parsing will be set as NaT\n",
      "        - If 'ignore', then invalid parsing will return the input\n",
      "    dayfirst : boolean, default False\n",
      "        Specify a date parse order if `arg` is str or its list-likes.\n",
      "        If True, parses dates with the day first, eg 10/11/12 is parsed as\n",
      "        2012-11-10.\n",
      "        Warning: dayfirst=True is not strict, but will prefer to parse\n",
      "        with day first (this is a known bug, based on dateutil behavior).\n",
      "    yearfirst : boolean, default False\n",
      "        Specify a date parse order if `arg` is str or its list-likes.\n",
      "    \n",
      "        - If True parses dates with the year first, eg 10/11/12 is parsed as\n",
      "          2010-11-12.\n",
      "        - If both dayfirst and yearfirst are True, yearfirst is preceded (same\n",
      "          as dateutil).\n",
      "    \n",
      "        Warning: yearfirst=True is not strict, but will prefer to parse\n",
      "        with year first (this is a known bug, based on dateutil beahavior).\n",
      "    \n",
      "        .. versionadded: 0.16.1\n",
      "    \n",
      "    utc : boolean, default None\n",
      "        Return UTC DatetimeIndex if True (converting any tz-aware\n",
      "        datetime.datetime objects as well).\n",
      "    box : boolean, default True\n",
      "    \n",
      "        - If True returns a DatetimeIndex\n",
      "        - If False returns ndarray of values.\n",
      "    format : string, default None\n",
      "        strftime to parse time, eg \"%d/%m/%Y\", note that \"%f\" will parse\n",
      "        all the way up to nanoseconds.\n",
      "    exact : boolean, True by default\n",
      "    \n",
      "        - If True, require an exact format match.\n",
      "        - If False, allow the format to match anywhere in the target string.\n",
      "    \n",
      "    unit : string, default 'ns'\n",
      "        unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
      "        integer or float number. This will be based off the origin.\n",
      "        Example, with unit='ms' and origin='unix' (the default), this\n",
      "        would calculate the number of milliseconds to the unix epoch start.\n",
      "    infer_datetime_format : boolean, default False\n",
      "        If True and no `format` is given, attempt to infer the format of the\n",
      "        datetime strings, and if it can be inferred, switch to a faster\n",
      "        method of parsing them. In some cases this can increase the parsing\n",
      "        speed by ~5-10x.\n",
      "    origin : scalar, default is 'unix'\n",
      "        Define the reference date. The numeric values would be parsed as number\n",
      "        of units (defined by `unit`) since this reference date.\n",
      "    \n",
      "        - If 'unix' (or POSIX) time; origin is set to 1970-01-01.\n",
      "        - If 'julian', unit must be 'D', and origin is set to beginning of\n",
      "          Julian Calendar. Julian day number 0 is assigned to the day starting\n",
      "          at noon on January 1, 4713 BC.\n",
      "        - If Timestamp convertible, origin is set to Timestamp identified by\n",
      "          origin.\n",
      "    \n",
      "        .. versionadded: 0.20.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ret : datetime if parsing succeeded.\n",
      "        Return type depends on input:\n",
      "    \n",
      "        - list-like: DatetimeIndex\n",
      "        - Series: Series of datetime64 dtype\n",
      "        - scalar: Timestamp\n",
      "    \n",
      "        In case when it is not possible to return designated types (e.g. when\n",
      "        any element of input is before Timestamp.min or after Timestamp.max)\n",
      "        return will have datetime.datetime type (or correspoding array/Series).\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Assembling a datetime from multiple columns of a DataFrame. The keys can be\n",
      "    common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
      "    'ms', 'us', 'ns']) or plurals of the same\n",
      "    \n",
      "    >>> df = pd.DataFrame({'year': [2015, 2016],\n",
      "                           'month': [2, 3],\n",
      "                           'day': [4, 5]})\n",
      "    >>> pd.to_datetime(df)\n",
      "    0   2015-02-04\n",
      "    1   2016-03-05\n",
      "    dtype: datetime64[ns]\n",
      "    \n",
      "    If a date does not meet the `timestamp limitations\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
      "    #timeseries-timestamp-limits>`_, passing errors='ignore'\n",
      "    will return the original input instead of raising any exception.\n",
      "    \n",
      "    Passing errors='coerce' will force an out-of-bounds date to NaT,\n",
      "    in addition to forcing non-dates (or non-parseable dates) to NaT.\n",
      "    \n",
      "    >>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
      "    datetime.datetime(1300, 1, 1, 0, 0)\n",
      "    >>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
      "    NaT\n",
      "    \n",
      "    Passing infer_datetime_format=True can often-times speedup a parsing\n",
      "    if its not an ISO8601 format exactly, but in a regular format.\n",
      "    \n",
      "    >>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000']*1000)\n",
      "    \n",
      "    >>> s.head()\n",
      "    0    3/11/2000\n",
      "    1    3/12/2000\n",
      "    2    3/13/2000\n",
      "    3    3/11/2000\n",
      "    4    3/12/2000\n",
      "    dtype: object\n",
      "    \n",
      "    >>> %timeit pd.to_datetime(s,infer_datetime_format=True)\n",
      "    100 loops, best of 3: 10.4 ms per loop\n",
      "    \n",
      "    >>> %timeit pd.to_datetime(s,infer_datetime_format=False)\n",
      "    1 loop, best of 3: 471 ms per loop\n",
      "    \n",
      "    Using a unix epoch time\n",
      "    \n",
      "    >>> pd.to_datetime(1490195805, unit='s')\n",
      "    Timestamp('2017-03-22 15:16:45')\n",
      "    >>> pd.to_datetime(1490195805433502912, unit='ns')\n",
      "    Timestamp('2017-03-22 15:16:45.433502912')\n",
      "    \n",
      "    .. warning:: For float arg, precision rounding might happen. To prevent\n",
      "        unexpected behavior use a fixed-width exact type.\n",
      "    \n",
      "    Using a non-unix epoch origin\n",
      "    \n",
      "    >>> pd.to_datetime([1, 2, 3], unit='D',\n",
      "                       origin=pd.Timestamp('1960-01-01'))\n",
      "    0    1960-01-02\n",
      "    1    1960-01-03\n",
      "    2    1960-01-04\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    pandas.DataFrame.astype : Cast argument to a specified dtype.\n",
      "    pandas.to_timedelta : Convert argument to timedelta.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1953,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>2009-12-14 10:53:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.021739</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>2009-12-14 10:53:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>3.478723</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2105</td>\n",
       "      <td>2009-12-14 10:52:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,1029,1061,1129,1263,1287,1293,1...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2009-12-14 10:52:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,31,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Animation|Children|Drama|Musical</td>\n",
       "      <td>3.702381</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1029</td>\n",
       "      <td>2009-12-14 10:52:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    query_movie_ids                            genres  \\\n",
       "0        1  1953,2105,31,1029,1061,1129,1263,1287,1293,133...                             Drama   \n",
       "1        1  1172,2105,31,1029,1061,1129,1263,1287,1293,133...             Action|Crime|Thriller   \n",
       "2        1  1172,1953,31,1029,1061,1129,1263,1287,1293,133...           Action|Adventure|Sci-Fi   \n",
       "3        1  1172,1953,2105,1029,1061,1129,1263,1287,1293,1...                             Drama   \n",
       "4        1  1172,1953,2105,31,1061,1129,1263,1287,1293,133...  Animation|Children|Drama|Musical   \n",
       "\n",
       "   avg_rating    year  candidate_movie_id            timestamp  rating  \n",
       "0    4.260870  1989.0                1172  2009-12-14 10:53:25       1  \n",
       "1    4.021739  1971.0                1953  2009-12-14 10:53:11       1  \n",
       "2    3.478723  1982.0                2105  2009-12-14 10:52:19       1  \n",
       "3    3.178571  1995.0                  31  2009-12-14 10:52:24       0  \n",
       "4    3.702381  1941.0                1029  2009-12-14 10:52:59       0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "merged = pd.read_csv('./merged_movielens.csv', names=tr_merged.columns)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def make_datasets(fpath_ary):\n",
    "    cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "    defaults = [[0], [''], [''], [], [], [0], []]\n",
    "\n",
    "    def to_dense(sp):\n",
    "        dense = tf.sparse_to_dense(sp.indices, sp.dense_shape, sp.values, '')\n",
    "        return tf.reshape(tf.to_int32(tf.string_to_number(dense)), [-1])\n",
    "\n",
    "    def to_sparse(dense):\n",
    "        idx = tf.where(tf.not_equal(dense, 0))\n",
    "        return tf.SparseTensor(indices=idx, dense_shape=dense.get_shape(), values=tf.gather_nd(dense, idx))\n",
    "\n",
    "    def parse_csv(value):\n",
    "        data = tf.decode_csv(value, record_defaults=defaults)\n",
    "        features = OrderedDict(zip(cols, data))\n",
    "        for col in ('query_movie_ids', 'genres'):\n",
    "            features[col] = tf.string_split([features[col]], ',')\n",
    "            features[col] = to_sparse(to_dense(features[col]))\n",
    "        return features \n",
    "\n",
    "    dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "    dataset = (dataset.map(parse_csv, num_parallel_calls=4)\n",
    "                      .padded_batch(3, OrderedDict(zip(cols, ([], [None], [None], [], [], [], []))))\n",
    "                      .shuffle(10, seed=seed)\n",
    "                      .repeat(2)\n",
    "              )\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    inputs = make_datasets(['./te_processed.batch.csv'])\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            print(sess.run(inputs)['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Columns with tf.feature_column.input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d40eac6f60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABjifwEt5/l8tchuzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d40eb49c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = pd.Series(minmax_scale(np.random.normal(0, 1, size=1000)))\n",
    "a.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    user_id = tf.feature_column.categorical_column_with_hash_bucket('user_id', hash_bucket_size=1000, dtype=tf.int32)\n",
    "    user_id = tf.feature_column.embedding_column(user_id, dimension=8)\n",
    "    avg_rating = tf.feature_column.numeric_column('avg_rating')\n",
    "    columns = [user_id, avg_rating]\n",
    "    \n",
    "    def make_datasets(fpath_ary):\n",
    "        cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "        defaults = [[0], [''], [''], [], [], [0], []]\n",
    "\n",
    "        def parse_csv(value):\n",
    "            data = tf.decode_csv(value, record_defaults=defaults)\n",
    "            features = OrderedDict(zip(cols, data))\n",
    "            # print(features)\n",
    "            return features\n",
    "        \n",
    "        dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "        dataset = (dataset.map(parse_csv, num_parallel_calls=4)\n",
    "                          .batch(3)\n",
    "                          # .padded_batch(3, OrderedDict(zip(cols, ([], [None], [None], [], [], [], []))))\n",
    "                          .shuffle(10, seed=seed)\n",
    "                          .repeat(1)\n",
    "                  )\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    inputs = make_datasets(['./te_processed.batch.csv'])\n",
    "    inputs = tf.feature_column.input_layer(inputs, columns)\n",
    "    # features = tf.parse_example(serialized_example, features=tf.feature_column.make_parse_example_spec(columns))\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Make Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "is_multi = [False, True, True, False, False, False, False]\n",
    "pd_dtypes = [int, str, str, float, float, int, float]\n",
    "types = ['int64_list', 'int64_list', 'int64_list', 'float_list', 'float_list', 'int64_list', 'float_list']\n",
    "tf_types = [tf.int64, tf.int64, tf.int64, tf.float32, tf.float32, tf.int64, tf.float32]\n",
    "def persist_example(fpath, tfpath):\n",
    "    with tf.python_io.TFRecordWriter(tfpath) as w:\n",
    "        for chunk in pd.read_csv(fpath, names=cols, dtype=dict(zip(cols, pd_dtypes)), chunksize=1000):\n",
    "            chunk['query_movie_ids'] = chunk.query_movie_ids.map(lambda r: map(int, r.split(',')))\n",
    "            chunk['genres'] = chunk.genres.map(lambda r: map(int, r.split(',')))\n",
    "            \n",
    "            for idx, r in chunk.iterrows():\n",
    "                ex = tf.train.Example()\n",
    "                for multi, col, tpe in zip(is_multi, cols, types):\n",
    "                    val = r[col]\n",
    "                    # ex.features.feature[col].int64_list or float_list or bytes_list\n",
    "                    feat_type = getattr(ex.features.feature[col], tpe)\n",
    "                    # extend function for multivalent columns, otherwise append\n",
    "                    append_or_extend = 'append' if not multi else 'extend'                    \n",
    "                    getattr(feat_type.value, append_or_extend)(val)\n",
    "                w.write(ex.SerializePartialToString())\n",
    "\n",
    "persist_example('./te_processed.csv', './data.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_example(ser_example):\n",
    "    # queue = tf.train.string_input_producer([fpath], num_epochs=1)\n",
    "    # _, ser_example = tf.TFRecordReader().read(queue)\n",
    "    # ser_example = tf.train.batch([ser_example], batch_size=10)\n",
    "    ctx_features = {col: tf.FixedLenFeature([], tf_tpe)\n",
    "                    for col, tf_tpe in zip(cols, tf_types) if col not in ('query_movie_ids', 'genres')}\n",
    "    seq_features = {col: tf.FixedLenSequenceFeature([], tf_tpe) \n",
    "                    for col, tf_tpe in [('query_movie_ids', tf.int64), ('genres', tf.int64)]}\n",
    "    context_dict, sequence_dict = tf.parse_single_sequence_example(ser_example, \n",
    "                                                                   context_features=ctx_features, \n",
    "                                                                   sequence_features=seq_features)\n",
    "    # for col, tpe in zip(cols, tf_types):\n",
    "    #     val = feature_dict[col]\n",
    "    #     feature_dict[col] = tf.sparse_to_dense(val.indices, val.dense_shape, val.values, name=col)\n",
    "    feature_dict = {}\n",
    "    feature_dict.update(context_dict)\n",
    "    feature_dict.update(sequence_dict)\n",
    "    ret = OrderedDict()\n",
    "    for c in cols:\n",
    "        ret[c] = feature_dict[c]\n",
    "    return tuple(ret.values())\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    dataset = tf.data.TFRecordDataset(['./data.tfrecord'])\n",
    "    dataset = dataset.map(decode_example).padded_batch(10, padded_shapes=([], [None], [None], [], [], [], []))\n",
    "    # dataset = dataset.batch(3)\n",
    "    iters = dataset.make_one_shot_iterator()\n",
    "    r = iters.get_next()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        print( sess.run(r) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional parse_example\n",
    "1. tf.train.Coordinator + tf.train.start_queue_runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import sparse_tensor\n",
    "import re\n",
    "\n",
    "def to_sparse(dense):\n",
    "    idx = tf.where(tf.not_equal(dense, 0))\n",
    "    return tf.SparseTensor(idx, tf.gather_nd(dense, idx), dense.get_shape())\n",
    "\n",
    "def make_example(val):\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature = {\n",
    "            'query_movie_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=val)),\n",
    "            'genres': tf.train.Feature(int64_list=tf.train.Int64List(value=val))\n",
    "        }\n",
    "    ))\n",
    "    return example\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    filename = \"tmp.tfrecords\"\n",
    "    if not os.path.exists(filename):\n",
    "        # os.remove(filename)\n",
    "        writer = tf.python_io.TFRecordWriter(filename)\n",
    "        with writer:\n",
    "            for idx, r in teProcessed.head().iterrows():\n",
    "                for col in ('query_movie_ids', 'genres'):\n",
    "                    val = list(map(int, re.split(',\\s*', r[col])))\n",
    "                    ex = make_example(val)\n",
    "                    writer.write(ex.SerializeToString())\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    filename_queue = tf.train.string_input_producer([\"tmp.tfrecords\"], num_epochs=1)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    batch = tf.train.batch(tensors=[serialized_example], batch_size=1)\n",
    "    features = {\n",
    "        'query_movie_ids': tf.VarLenFeature(tf.int64),\n",
    "        'genres': tf.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    data = tf.parse_example(batch, features)\n",
    "    query_movie_ids = data['query_movie_ids']\n",
    "    embbedding = tf.Variable(tf.glorot_uniform_initializer()([9125]), dtype=tf.float32)\n",
    "    print(query_movie_ids.dense_shape)\n",
    "    # r = tf.layers.dense(query_movie_ids, 10)\n",
    "    # emb_query = tf.nn.embedding_lookup_sparse([embbedding], query_movie_ids, None, combiner='sqrtn')\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        try:\n",
    "            print(sess.run(data))\n",
    "            pass\n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            coord.request_stop(e)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    labels = tf.constant(np.ones([10, 8]))\n",
    "    pred = tf.concat([tf.Variable(tf.ones(shape=[1, 8]), trainable=False), tf.Variable(tf.truncated_normal([9, 8]))], 0)\n",
    "    loss = tf.losses.mean_squared_error(predictions=pred, labels=labels)\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(pred.eval())\n",
    "        for i in range(1000):\n",
    "            sess.run([train_op])\n",
    "        print()\n",
    "        print(pred.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.zeros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
